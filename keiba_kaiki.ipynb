{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c1d11-11d7-4133-962b-16a3abd0fc57",
   "metadata": {},
   "source": [
    "# 基本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcecf86-6986-4df6-949b-1889be42baf1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import re \n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b1cc1f-149b-4fa6-b5de-418cba0ad75f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_19 = pd.read_pickle('results_19.pickle')\n",
    "results_20 = pd.read_pickle('results_20.pickle')\n",
    "results_21 = pd.read_pickle('results_21.pickle')\n",
    "results_all = pd.read_pickle('results_all.pickle')\n",
    "results_all.drop([\"cource_len\",\"data\"], axis=1, inplace=True)\n",
    "\n",
    "horse_results = pd.read_pickle('horse_results_19.pickle')\n",
    "horse_results_20 = pd.read_pickle('horse_results_20.pickle')\n",
    "horse_results_21 = pd.read_pickle('horse_results_21.pickle')\n",
    "horse_results_all = \n",
    "\n",
    "peds = pd.read_pickle('peds-Copy1.pickle')\n",
    "peds_all = pd.read_pickle('peds_all.pickle')\n",
    "n_peds_all = pd.read_pickle('n_peds_all')\n",
    "n_peds_all2 = pd.read_pickle('n_peds_all2.pickle')\n",
    "\n",
    "#r.data_cの馬番をsortしたもの　リークをなくすため\n",
    "r_data_sort = pd.read_pickle(\"r_data_sort.pickle\")\n",
    "\n",
    "return_tables_19 = pd.read_pickle('Return_tables_19.pickle')\n",
    "return_tables_20 = pd.read_pickle('Return_tables_20.pickle')\n",
    "return_tables_21 = pd.read_pickle('Return_tables_21.pickle')\n",
    "return_tables_all = pd.read_pickle(\"Return_tables_all.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84d214-23b1-43d9-a37e-5705de42bfef",
   "metadata": {},
   "source": [
    "# 関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfedbbe-ae22-4661-8077-a3e6cd1d5a09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#min_thresholdの値から1までを100等分する\n",
    "def gain(return_func, X, n_samples=100, range_=[0.5, 3.5]):\n",
    "    gain = {}\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        threshold = range_[1] * i / n_samples + range_[0] * (1 - (i / n_samples))\n",
    "        n_bets, return_rate, n_hits, std = return_func(X, threshold)\n",
    "        if n_bets > 2:\n",
    "            gain[threshold] = {\"return_rate\":return_rate,\n",
    "                                \"n_hits\":n_hits,\n",
    "                                \"std\":std,\n",
    "                                \"n_bets\":n_bets}\n",
    "    return pd.DataFrame(gain).T\n",
    "\n",
    "# yearに値を入れればいい\n",
    "def race_id_c(year):\n",
    "    race_id_list = []\n",
    "    \n",
    "    race_id_head = year\n",
    "    for place in range(1,11,1):\n",
    "        for kai in range(1,6,1):\n",
    "            for day in range(1,13,1):\n",
    "                for r in range(1,13,1):\n",
    "                    race_id = str(place).zfill(2) + str(kai).zfill(2) +\\\n",
    "                    str(day).zfill(2) + str(r).zfill(2)\n",
    "                    race_ids = race_id_head + race_id\n",
    "                    race_id_list.append(race_ids)\n",
    "    return race_id_list\n",
    "\n",
    "def split_data(df, test_size=0.3):\n",
    "    sorted_id_list = df.sort_values(\"date\").index.unique()\n",
    "    train_id_list = sorted_id_list[: round(len(sorted_id_list) * (1 - test_size))]\n",
    "    test_id_list = sorted_id_list[round(len(sorted_id_list) * (1 - test_size)) :]\n",
    "    train = df.loc[train_id_list]#.drop(['date'], axis=1)\n",
    "    test = df.loc[test_id_list]#.drop(['date'], axis=1)\n",
    "    return train, test\n",
    "\n",
    "def plot(df, label=' '):\n",
    "    plt.fill_between(df.index, y1=df['return_rate']-df['std'],\n",
    "        y2=df['return_rate']+df['std'],alpha=0.3)\n",
    " \n",
    "    plt.plot(df.index, df['return_rate'], label=label)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "place_dict = {\n",
    "    '札幌':'01',  '函館':'02',  '福島':'03',  '新潟':'04',  '東京':'05', \n",
    "    '中山':'06',  '中京':'07',  '京都':'08',  '阪神':'09',  '小倉':'10'\n",
    "}\n",
    "\n",
    "race_type_dict = {\n",
    "    '芝': '芝', 'ダ': 'ダート', '障': '障害'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb4068-bfb9-4e51-b4d2-bb13837b2b46",
   "metadata": {},
   "source": [
    "# Dataprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532359f1-fd45-49b4-995f-2c4120f79dd6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.data = pd.DataFrame() # raw data\n",
    "        self.data_p = pd.DataFrame() #after preprocessing\n",
    "        self.data_h = pd.DataFrame() #after merging horse_results\n",
    "        self.data_pe = pd.DataFrame() #after merging peds\n",
    "        self.data_c = pd.DataFrame() #after processing categorical features\n",
    "        self.data_ = pd.DataFrame()\n",
    "        #self.no_peds #親データがないhorse_id_list\n",
    "    \n",
    "    # 馬の過去成績のデータ追加    \n",
    "    def merge_horse_results(self, hr, n_samples_list=[5, 9, 'all']):\n",
    "        self.data_h = self.data_p.copy()\n",
    "        for n_samples in n_samples_list:\n",
    "            self.data_h = hr.merge_all(self.data_h, n_samples=n_samples)\n",
    "            \n",
    "        #self.data_h[\"interval\"] = (self.data_h[\"data\"] - self.data_h[\"latest\"]).dt.days\n",
    "        self.data_h.drop([\"開催\"],axis=1, inplace=True)\n",
    "    \n",
    "    # 馬の親データの追加                \n",
    "    def merge_peds(self, peds):\n",
    "        self.data_pe = self.data_h.merge(peds,left_on='horse_id',\n",
    "        right_index=True, how='left')\n",
    "        \n",
    "        self.no_peds = self.data_pe[self.data_pe['peds_0'].isnull()]\\\n",
    "            ['horse_id'].unique()\n",
    "        if len(self.no_peds) > 0:\n",
    "            print('scrape peds at horse_id_list \"no_peds\"')\n",
    "    \n",
    "    # 質的変数への変換        \n",
    "    def process_categorical(self, le_horse, le_jockey, results_m):\n",
    "        df = self.data_pe.copy()\n",
    "        \n",
    "        #ラベルエンコーディング　horse_id,jockey_idを0始まりの整数に変換\n",
    "        mask_horse = df['horse_id'].isin(le_horse.classes_)\n",
    "        new_horse_id = df['horse_id'].mask(mask_horse).dropna().unique()\n",
    "        le_horse.classes_ = np.concatenate([le_horse.classes_, new_horse_id])\n",
    "        df['horse_id'] = le_horse.transform(df['horse_id'])\n",
    "        \n",
    "        mask_jockey = df['jockey_id'].isin(le_jockey.classes_)\n",
    "        new_jockey_id = df['jockey_id'].mask(mask_jockey).dropna().unique()\n",
    "        le_jockey.classes_ = np.concatenate([le_jockey.classes_, new_jockey_id])\n",
    "        df['jockey_id'] = le_jockey.transform(df['jockey_id'])\n",
    "        \n",
    "        df[\"horse_id\"] = df[\"horse_id\"].astype('category')\n",
    "        df[\"jockey_id\"] = df[\"jockey_id\"].astype('category')\n",
    "        \n",
    "        weathers = results_m['weather'].unique()\n",
    "        race_types = results_m['race_type'].unique()\n",
    "        ground_states = results_m['ground_state'].unique()\n",
    "        sexes = results_m['性'].unique()\n",
    "        df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "        df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "        df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "        df['性'] = pd.Categorical(df['性'], sexes)\n",
    "        \n",
    "        df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "        #race_idを軸に馬番をsort\n",
    "        df = df.reset_index().sort_values([\"index\",\"馬番\"]).set_index('index')\n",
    "        df.index.name = None\n",
    "        \n",
    "        self.data_c = df\n",
    "     \n",
    "    \n",
    "# Results class \n",
    "# 足りないhorse_idをスクレイプした際は確認したのちdef to_data_frameを使う必要あり\n",
    "class Results(DataProcessor):\n",
    "    def __init__(self, results):\n",
    "        super(Results, self).__init__()\n",
    "        self.data = results\n",
    "    \n",
    "    # path_listはpickle名\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(race_id_list, pre_race_results={}):\n",
    "        race_results = pre_race_results\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            if race_id in race_results.key():\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "                df = pd.read_html(url)[0]\n",
    "                html = requests.get(url)\n",
    "                html.encode = \"EUC-JP\"\n",
    "                soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "                \n",
    "                texts = (\n",
    "                    soup.find(\"div\", attrs={\"class\" : \"data_intro\"}).find_all(\"p\")[0].tesxt\n",
    "                    + soup.find(\"div\", attrs={\"class\" : \"data_intro\"}).find_all(\"p\")[1].tesxt\n",
    "                )\n",
    "                info = re.findall(r\"\\w+\", texts)\n",
    "                for text in info:\n",
    "                    if text in [\"芝\", \"ダート\"]:\n",
    "                        df[\"race_type\"] = [text] * len(df)\n",
    "                    if \"障\" in text:\n",
    "                        df[\"race_type\"] = [\"障害\"] * len(df)\n",
    "                    if \"m\" in text:\n",
    "                        df[\"course_len\"] = [int(re.findall(r\"\\d+\", text)[0])] * len(df)\n",
    "                    if text in [\"良\", \"稍重\", \"稍\", \"重\", \"不良\"]:\n",
    "                        df[\"ground_state\"] = [text] * len(df)\n",
    "                    if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                        df[\"weather\"] = [text] * len(df)\n",
    "                    if \"年\" in text:\n",
    "                        df[\"date\"] = [text] * len(df)\n",
    "                        \n",
    "                #馬ID、騎手IDをスクレイピング\n",
    "                horse_id_list = []\n",
    "                horse_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/horse\")}\n",
    "                )\n",
    "                for a in horse_a_list:\n",
    "                    horse_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    horse_id_list.append(horse_id[0])\n",
    "                jockey_id_list = []\n",
    "                jockey_a_list = soup.find(\"table\", attrs={\"summary\": \"レース結果\"}).find_all(\n",
    "                    \"a\", attrs={\"href\": re.compile(\"^/jockey\")}\n",
    "                )\n",
    "                for a in jockey_a_list:\n",
    "                    jockey_id = re.findall(r\"\\d+\", a[\"href\"])\n",
    "                    jockey_id_list.append(jockey_id[0])\n",
    "                df[\"horse_id\"] = horse_id_list\n",
    "                df[\"jockey_id\"] = jockey_id_list\n",
    "\n",
    "                #インデックスをrace_idにする\n",
    "                df.index = [race_id] * len(df)\n",
    "                \n",
    "                race_results[race_id] = df \n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "        return race_results\n",
    "        # 一度dataframe型に直さずに出力を返す        \n",
    "        #return race_results\n",
    "        \n",
    "    def to_data_frame(race_results):\n",
    "        race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "\n",
    "        return race_results_df\n",
    "        \n",
    "        \n",
    "        \n",
    "    # to_dataframe関数で出力後にdataframe型に変換が可能            \n",
    "    #def to_dataframe(race_results):\n",
    "        #race_results_df = pd.concat([race_results[key] for key in race_results])\n",
    "        \n",
    "        #r.data_rr = race_results_df                    \n",
    "                \n",
    "    # regressionをtrueにすることでsecond,着順が表示され回帰が行える。\n",
    "    def preprocessing(self, regression=False):\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "        df['rank'] = df['着順'].map(lambda x: 1 if x < 4 else 0)\n",
    "\n",
    "        # 性齢を性と年齢に分ける\n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける (馬体重修正するかも)\n",
    "        df[\"体重\"] = df[\"馬体重\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "        df[\"体重変化\"] = df[\"馬体重\"]\\\n",
    "            .str.split(\"(\", expand=True)[1].replace(\"前計不\", \"0\").str[:-1].astype(dtype = int)\n",
    "\n",
    "        # データをint, floatに変換\n",
    "        df[\"単勝\"] = df[\"単勝\"].astype(float)\n",
    "        df['course_len'] = df['course_len'].astype(float) // 100\n",
    "\n",
    "        # 不要な列を削除\n",
    "        #回帰子を作るために一時的に着順,タイムの列を削除しない。\n",
    "        #df.drop([\"タイム\", \"着差\", \"調教師\", \"性齢\", \"馬体重\",\"馬名\",\"騎手\",\"人気\",\"着順\"], axis=1, inplace=True)\n",
    "        df.drop([\"着差\", \"調教師\", \"性齢\", \"馬体重\",\"馬名\",\"騎手\",\"人気\"], axis=1, inplace=True)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y年%m月%d日\")\n",
    "        \n",
    "        df[\"タイム\"].fillna(\"0\", inplace=True)\n",
    "        df[\"a\"] = df[\"タイム\"].map(lambda x:re.sub(r\"\\D\", \"\", x)).astype(str)\n",
    "        df[\"second\"] = df[\"a\"].map(lambda x: 0 if x==\"0\" \\\n",
    "        else (int(x[0]) * 60) + int(x[1:3]) + int(x[1:])/10).astype(float)\n",
    "        df.drop(\"a\", axis=1 ,inplace=True)\n",
    "        df.drop([\"タイム\"],axis=1, inplace=True)\n",
    "        \n",
    "        df[\"rls\"] = df[\"second\"]\\\n",
    "        .map(lambda x: np.sqrt(np.log(x)))\n",
    "        \n",
    "        df['開催'] = df.index.map(lambda x: str(x)[4:6])\n",
    "        \n",
    "        df[\"n_horses\"] = df.index.map(df.index.value_counts())\n",
    "        \n",
    "        if regression == True:\n",
    "            self.data_p = df\n",
    "        else:\n",
    "            self.data_p = df.drop([\"second\",\"着順\",\"rls\"],axis=1)\n",
    "    \n",
    "    def process_categorical(self):\n",
    "        self.le_horse = LabelEncoder().fit(self.data_pe['horse_id'])\n",
    "        self.le_jockey = LabelEncoder().fit(self.data_pe['jockey_id'])\n",
    "        super().process_categorical(self.le_horse, self.le_jockey, self.data_pe)\n",
    "  \n",
    "    \n",
    "# ShutubaTable class        \n",
    "class ShutubaTable(DataProcessor):\n",
    "    def __init__(self, shutuba_tables):\n",
    "        super(ShutubaTable, self).__init__()\n",
    "        self.data = shutuba_tables\n",
    "        \n",
    "    @classmethod    \n",
    "    def scrape(cls, race_id_list, date):\n",
    "        data = pd.DataFrame()\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            \n",
    "            url = 'https://race.netkeiba.com/race/shutuba.html?race_id=' + race_id\n",
    "            df = pd.read_html(url)[0]\n",
    "            df = df.T.reset_index(level=0, drop=True).T\n",
    "            \n",
    "            html = requests.get(url)\n",
    "            html.encoding = \"EUC-JP\"\n",
    "            soup = BeautifulSoup(html.text, \"html.parser\")\n",
    "            \n",
    "            texts = soup.find(\"div\", attrs={\"class\":\"RaceData01\"}).text\n",
    "            texts = re.findall(r\"\\w+\", texts)\n",
    "            for text in texts:\n",
    "                if 'm' in text:\n",
    "                    df['course_len'] = [int(re.findall(r'\\d+', text)[0])] * len(df)\n",
    "                if text in [\"曇\", \"晴\", \"雨\", \"小雨\", \"小雪\", \"雪\"]:\n",
    "                    df[\"weather\"] = [text] * len(df)\n",
    "                if text in [\"良\", \"稍重\", \"稍\", \"重\"]:\n",
    "                    df[\"ground_state\"] = [text] * len(df)\n",
    "                if '不' in text:\n",
    "                    df[\"ground_state\"] = ['不良'] * len(df)\n",
    "                if '芝' in text:\n",
    "                    df['race_type'] = ['芝'] * len(df)\n",
    "                if '障' in text:\n",
    "                    df['race_type'] = ['障害'] * len(df)\n",
    "                if 'ダ' in text:\n",
    "                    df['race_type'] = ['ダート'] * len(df)\n",
    "            df['date'] = [date] * len(df)\n",
    "            \n",
    "            # horse_id\n",
    "            horse_id_list = []\n",
    "            horse_td_list = soup.find_all(\"td\", attrs={'class': 'HorseInfo'})\n",
    "            for td in horse_td_list:\n",
    "                horse_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                horse_id_list.append(horse_id)\n",
    "            # jockey_id\n",
    "            jockey_id_list = []\n",
    "            jockey_td_list = soup.find_all(\"td\", attrs={'class': 'Jockey'})\n",
    "            for td in jockey_td_list:\n",
    "                jockey_id = re.findall(r'\\d+', td.find('a')['href'])[0]\n",
    "                jockey_id_list.append(jockey_id)\n",
    "            df['horse_id'] = horse_id_list\n",
    "            df['jockey_id'] = jockey_id_list\n",
    "\n",
    "            df.index = [race_id] * len(df)\n",
    "            data = data.append(df)\n",
    "            time.sleep(1)\n",
    "        return cls(data)\n",
    "\n",
    "    #disclosuer = Trueで馬体重が公開されていないデータでも予測が行える        \n",
    "    def preprocessing(self, disclosuer=False):\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df[\"性\"] = df[\"性齢\"].map(lambda x: str(x)[0])\n",
    "        df[\"年齢\"] = df[\"性齢\"].map(lambda x: str(x)[1:]).astype(int)\n",
    "\n",
    "        # 馬体重を体重と体重変化に分ける\n",
    "        if disclosuer == True:\n",
    "            df[\"体重\"] = 470\n",
    "            df[\"体重変化\"] = 0\n",
    "        else:\n",
    "            df = df[df[\"馬体重(増減)\"] != '--']\n",
    "            df[\"体重\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[0].astype(int)\n",
    "\n",
    "            df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1].replace(\"前計不)\", \"0)\").str[:-1].astype(dtype = int)\n",
    "            \n",
    "        \n",
    "        #df[\"体重変化\"] = df[\"馬体重(増減)\"].str.split(\"(\", expand=True)[1]\n",
    "        #df[\"体重変化\"] = df[\"体重変化\"].replace(\"前計不)\", \"0)\")\n",
    "        #df[\"体重変化\"] = df[\"体重変化\"].str[:-1].astype(int)\n",
    "        \n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        \n",
    "        df['枠'] = df['枠'].astype(int)\n",
    "        df['馬番'] = df['馬番'].astype(int)\n",
    "        df['斤量'] = df['斤量'].astype(int)\n",
    "        \n",
    "        df[\"開催\"] = df.index.map(lambda x:str(x)[4:6])\n",
    "        \n",
    "        df[\"n_horses\"] = df.index.map(df.index.value_counts())\n",
    "\n",
    "        # 不要な列を削除\n",
    "        df = df[['枠', '馬番', '斤量', 'course_len', 'weather','race_type',\n",
    "        'ground_state', 'date', 'horse_id', 'jockey_id', '性', '年齢',\n",
    "        '体重', '体重変化',\"開催\",\"n_horses\"]]\n",
    "        \n",
    "        self.data_p = df.rename(columns={'枠': '枠番'})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03a6d6-588a-4e98-9dae-c48d53e478b7",
   "metadata": {},
   "source": [
    "# Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6704ba-5b0e-4cea-b6c0-8463a25c6c02",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Return:\n",
    "    def __init__(self, return_tables):\n",
    "        self.return_tables = return_tables\n",
    "    \n",
    "    # path_listはpathではなく保存名で良い\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "        \n",
    "    @staticmethod\n",
    "    def scrape(race_id_list):\n",
    "        return_tables = {}\n",
    "        for race_id in tqdm(race_id_list):\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/race/\" + race_id\n",
    "\n",
    "                #普通にスクレイピングすると複勝やワイドなどが区切られないで繋がってしまう。\n",
    "                #そのため、改行コードを文字列brに変換して後でsplitする\n",
    "                f = urlopen(url)\n",
    "                html = f.read()\n",
    "                html = html.replace(b'<br />', b'br')\n",
    "                dfs = pd.read_html(html)\n",
    "\n",
    "                #dfsの1番目に単勝〜馬連、2番目にワイド〜三連単がある\n",
    "                df = pd.concat([dfs[1], dfs[2]])\n",
    "\n",
    "                df.index = [race_id] * len(df)\n",
    "                return_tables[race_id] = df\n",
    "                time.sleep(0.7)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる\n",
    "        return_tables_df = pd.concat([return_tables[key] for key in return_tables])\n",
    "        return return_tables_df\n",
    "    \n",
    "    @property\n",
    "    def sanrenpuku(self):\n",
    "        sanrenpuku = self.return_tables[self.return_tables[0] == \"三連複\"][[1,2]]\n",
    "        wins = sanrenpuku[1].str.split('-', expand=True)[[0,1,2]].add_prefix('wins_')\n",
    "        return_ = sanrenpuku[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x:pd.to_numeric(x.str.replace(',',''), errors='coerce'))\n",
    "    \n",
    "    @property\n",
    "    def sanrentan(self):\n",
    "        sanrentan = self.return_tables[self.return_tables[0] == \"三連単\"][[1,2]]\n",
    "        wins = sanrentan[1].str.split('→', expand=True)[[0,1,2]].add_prefix('wins_')\n",
    "        return_ = sanrentan[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x.str.replace(',',''), errors='coerce'))\n",
    "    \n",
    "    @property #本来ならRetrun(return_tables).fukusho(retrun_tables)の形だが、\n",
    "    #Retrun(return_tables).fukushoで扱える\n",
    "    def fukusho(self):\n",
    "        fukusho = self.return_tables[self.return_tables[0] == '複勝'][[1,2]]\n",
    "        wins = fukusho[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        wins.columns = ['win_0','win_1','win_2']\n",
    "        returns = fukusho[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        returns.columns = ['return_0','return_1','return_2']\n",
    "        df = pd.concat([wins, returns], axis=1)\n",
    "        for column in df.columns:\n",
    "            df[column] = df[column].str.replace(',', \"\")\n",
    "        return df.fillna(0).astype(int)\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def wide(self):\n",
    "        wide = self.return_tables[self.return_tables[0] == \"ワイド\"][[1,2]]\n",
    "        wins = wide[1].str.split('br', expand=True)[[0,1,2]]\n",
    "        wins = wins.stack().str.split('-', expand=True).add_prefix('win_')\n",
    "        return_ = wide[2].str.split('br', expand=True)[[0,1,2]]\n",
    "        return_ = return_.stack().rename(\"return\")\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x.str.replace(\",\",\"\"),errors='coerce'))\n",
    "    \n",
    "    @property #単勝に対して予測を行う\n",
    "    def tansho(self):\n",
    "        tansho = self.return_tables[self.return_tables[0] == '単勝'][[1,2]]\n",
    "        tansho.columns = ['win','return']\n",
    "        \n",
    "        for column in tansho.columns:\n",
    "            tansho[column] = pd.to_numeric(tansho[column], errors='coerce')\n",
    "        return tansho\n",
    "    \n",
    "    @property\n",
    "    def umaren(self):\n",
    "        umaren = self.return_tables[self.return_tables[0] == \"馬連\"][[1,2]]\n",
    "        wins = umaren[1].str.split('-', expand=True)[[0,1]].add_prefix(\"win_\")\n",
    "        #wins.columns = ([\"win_1\",\"win_2\"])#.add_prefix(\"win_\")\n",
    "        return_ = umaren[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
    "    \n",
    "    @property\n",
    "    def umatan(self):\n",
    "        umatan = self.return_tables[self.return_tables[0] == '馬単'][[1,2]]\n",
    "        wins = umatan[1].str.split(\"→\", expand=True)[[0,1]].add_prefix(\"win_\")\n",
    "        return_ = umatan[2].rename('return')\n",
    "        df = pd.concat([wins, return_], axis=1)\n",
    "        return df.apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
    "        \n",
    "        #for column in umaren.columns:\n",
    "            #umaren[column] = pd.to_numeric(umaren[column], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecc6ce-23f0-4ad5-a9e8-ff8cf0ea35fd",
   "metadata": {},
   "source": [
    "# ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762a4c74-7ab6-47bc-83f4-31e7ce2e5325",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#このクラス内において、第一引数にあたるxにはX_testのようなテストデータを入れる(単勝項目があるもの)\n",
    "# return_tables_path = pickle_path\n",
    "class ModelEvaluator:\n",
    "    \n",
    "    def __init__(self, model, return_tables_list):\n",
    "        self.model = model\n",
    "        self.rt = Return.read_pickle(return_tables_list)\n",
    "        self.fukusho = self.rt.fukusho\n",
    "        self.tansho = self.rt.tansho\n",
    "        self.umaren = self.rt.umaren\n",
    "        self.umatan = self.rt.umatan\n",
    "        self.wide = self.rt.wide\n",
    "        self.sanrentan = self.rt.sanrentan\n",
    "        self.sanrenpuku = self.rt.sanrenpuku\n",
    "        #self.std = std\n",
    "\n",
    "    #3着以内に入る確率を予測、表示\n",
    "    #X = Objective Variable type\n",
    "    #引数train 項目に\"単勝\"があればdropする\n",
    "    #引数std 標準偏差の計算を行う\n",
    "    #引数minmax 出力された値のスケーリングを行う\n",
    "    def predict_proba(self, X, train=True, std=True, minmax=False):\n",
    "        #相対評価工程\n",
    "        if train:\n",
    "            proba = pd.Series(self.model.predict_proba(X.drop([\"単勝\"], axis=1))[:,1], index=X.index)\n",
    "        else:\n",
    "            proba = pd.Series(self.model.predict_proba(X, axis=1)[:,1], index=X.index)\n",
    "        #proba = pd.Series(self.model.predict_proba(X)[:,1], index=X.index)\n",
    "        if std:\n",
    "            standerd_scaler = lambda x: (x - x.mean()) / x.std()\n",
    "            proba = proba.groupby(level=0).transform(standerd_scaler)\n",
    "            \n",
    "        #min-maxスケーリング\n",
    "        if minmax:\n",
    "            proba = (proba - proba.min()) / (proba.max() - proba.min())\n",
    "        return proba \n",
    "    \n",
    "    #閾値(threshold)を設定する　デフォルト0.6\n",
    "    #predict_probaで確率がthreshold以上であれば1を出力(1=賭ける)\n",
    "    def predict(self, X, threshold=0.6):\n",
    "        y_pred = self.predict_proba(X)\n",
    "        self.proba = y_pred\n",
    "        return [0 if p<threshold else 1 for p in y_pred]\n",
    "        \n",
    "    #auc曲線のスコアを求める\n",
    "    def roc_auc_score(self, y_test, X_test):\n",
    "        return roc_auc_score(y_test, lgb_clf.predict_proba(X_test.drop([\"単勝\"], axis=1))[:, 1])\n",
    "    \n",
    "    #各成分の特徴量の強さの表示 デフォルト20\n",
    "    def feature_importance(self, X, n_display=20):\n",
    "        importances = pd.DataFrame({\"features\":X.columns, \n",
    "                                  \"importance\":self.model.feature_importances_})\n",
    "        return importances.sort_values('importance', ascending=False)[:n_display]\n",
    "    \n",
    "    #閾値を通して1と判定されたものだけをpred_tableとして出力する\n",
    "    def pred_table(self, X, threshold=0.6, bet_only = True):\n",
    "        pred_table = X.copy()[['馬番',\"単勝\"]]\n",
    "        pred_table['pred'] = self.predict(X, threshold)\n",
    "        pred_table[\"score\"] = self.proba\n",
    "        return pred_table[pred_table[\"pred\"] == 1]\n",
    "  \n",
    "    # umabanはint型で入力する必要がある\n",
    "    def bet(self, race_id, kind, umaban, amount):\n",
    "        if kind == \"tansho\":\n",
    "            rt_a = self.tansho.loc[race_id]\n",
    "            return_ = (rt_a['win'] == umaban) * amount/100 * rt_a['return']\n",
    "        elif kind == \"fukusho\":\n",
    "            rt_a = self.fukusho.loc[race_id]\n",
    "            return_ = ((rt_a[[\"win_0\",\"win_1\",\"win_2\"]] == umaban).values * \\\n",
    "            rt_a[['return_0',\"return_1\",\"return_2\"]]).sum() * amount/100\n",
    "        elif kind == \"umaren\":\n",
    "            rt_a = self.umaren.loc[race_id]\n",
    "            return_ = (set(rt_a[[\"win_0\",\"win_1\"]]) == set(umaban)) * rt_a[\"return\"] *\\\n",
    "            amount/100\n",
    "        elif kind == \"umatan\":\n",
    "            rt_a = self.umatan.loc[race_id]\n",
    "            return_ = (list(rt_a[[\"win_0\",\"win_1\"]]) == list(umaban)) * rt_a[\"return\"] *\\\n",
    "            amount/100\n",
    "        elif kind == \"wide\":\n",
    "            rt_a = self.wide.loc[race_id]\n",
    "            return_ = (rt_a[[\"win_0\",\"win_1\"]].apply(lambda x:set(x)==set(umaban),axis=1)) *\\\n",
    "            rt_a[\"return\"] / 100 * amount\n",
    "        elif kind == \"sanrentan\":\n",
    "            rt_a = self.sanrentan.loc[race_id]\n",
    "            return_ = (list(rt_a[[\"wins_0\",\"wins_1\",\"wins_2\"]])==list(umaban))*\\\n",
    "            rt_a[\"return\"] / 100 * amount \n",
    "        elif kind == 'sanrenpuku':\n",
    "            rt_a = self.sanrenpuku.loc[race_id]\n",
    "            return_ = (set(rt_a[[\"wins_0\",\"wins_1\",\"wins_2\"]])==set(umaban))*\\\n",
    "            rt_a[\"return\"]/100 * amount\n",
    "        elif not (return_ >= 0):\n",
    "            return_ = amount\n",
    "        return return_\n",
    "                \n",
    "\n",
    "    #items=True　にすることで、項目名の確認が可能になる。\n",
    "    #ただし、Trueの状態では、gain関数に利用することができないのでFalseの必要がある  \n",
    "    def fukusho_return(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(np.sum([\\\n",
    "                self.bet(race_id,\"fukusho\",umaban,1) for umaban in preds[\"馬番\"]\\\n",
    "                                      ]))\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        \n",
    "        if items == True:    \n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "    \n",
    "    def tansho_return(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        self.sample = pred_table\n",
    "        n_bets = len(pred_table)\n",
    "        \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum([self.bet(race_id,\"tansho\",umaban,1) for umaban in preds[\"馬番\"]])\n",
    "            )\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std     \n",
    " \n",
    "    def tansho_return_proper(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = len(pred_table)\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_list.append(\n",
    "                np.sum(preds.apply(lambda x:self.bet(\n",
    "                race_id, \"tansho\", x[\"馬番\"], 1/x[\"単勝\"]), axis=1)))\n",
    "        bet_money = (1 / pred_table[\"単勝\"]).sum()\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / bet_money\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / bet_money\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "    \n",
    "    def umaren_box(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        \n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query('pred == 1')\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umaren\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "                \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:    \n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "    \n",
    "    def umatan_box(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umatan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "            \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets            \n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "\n",
    "        \n",
    "    def wide_box(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "            \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(presd_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"wide\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "                    \n",
    "        std = np.sum(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "            \n",
    "    def sanrentan_box(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "            \n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            if len(prefs) < 3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in permutations(preds[\"馬番\"], 3):\n",
    "                    return_ += self.bet(race_id, \"sanrentan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "                \n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "            \n",
    "    def sanrenpuku_box(self, X, threshold=0.6, items=False):\n",
    "        pred_table = self.pred_table(X, threshold)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "            \n",
    "        for race_id, preds in pred_table.groupbu(level=0):\n",
    "            return_ = 0\n",
    "            if len(preds) < 3:\n",
    "                continue\n",
    "            else:\n",
    "                for umaban in combinations(preds[\"馬番\"], 3):\n",
    "                    return_ += self.bet(race_id ,\"sanrenpuku\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def umaren_nagashi(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_lsit = []\n",
    "            \n",
    "        for race_id, preds in pred_table.groupbu(level=0):\n",
    "            return_ = 0\n",
    "            preds_ijku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values(\"score\", ascending=False)\\\n",
    "                .iloc[1:(n_aite+1)][\"馬番\"]\n",
    "                return_ = preds_aite.map(\n",
    "                race_id, \"umaban\", [preds_jiku[\"馬番\"].values[0], x], 1).sum()\n",
    "                n_bets += n_aite\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umaban\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])    \n",
    "        return_rate = np.sum(return_list) / n_bets \n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def umatan_nagashi(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshold, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_lsit = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values(\"score\", ascending=False).\\\n",
    "                iloc[1: (n_aite+1)][\"馬番\"]\n",
    "                return_ = preds_aite.map(\n",
    "                lambda x: self.bet(race_id, \"umatan\", [preds_jiku[\"馬番\"].values[0], x], 1)).sum()\n",
    "                n_bets += n_aite\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in permutations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"umatan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "            return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def wide_nagashi(self, X, threshold=0.6, n_aite=5, items=False):\n",
    "        pred_table = self.pred_table(X, threshpld, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_list = []\n",
    "        for race_id, preds in pred_table.groupby(level=0):\n",
    "            return_ = 0\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                preds_aite = preds.sort_values(\"scoer\", ascending=False).iloc[1:(n_aite+1)][\"馬番\"]\n",
    "                return_ = preds_aite.map(lambda x: self.bet(race_id, \"wide\", [preds_jiku[\"馬番\"].values[0], x], 1)).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 2:\n",
    "                for umaban in combinations(preds_jiku[\"馬番\"], 2):\n",
    "                    return_ += self.bet(race_id, \"wide\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_list) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "        \n",
    "    def sanrentan_nagshi(self, X, thresholf=1.5, n_aite=7, items=False):\n",
    "        pred_table = self.pred_table(X, thresholod, bet_only=False)\n",
    "        n_bets = 0\n",
    "        return_ = []\n",
    "        for race_id, preds in pred_table.groupbu(level=0):\n",
    "            preds_jiku = preds.query(\"pred == 1\")\n",
    "            if len(preds_jiku) == 1:\n",
    "                continue\n",
    "            elif len(preds_jiku) == 2:\n",
    "                preds_aite = preds.sort_values(\"score\", ascending=False).\\\n",
    "                iloc[2: (n_aite+2)][\"馬番\"]\n",
    "                return_ = preds_aite.map(lambda x: self.bet(race_id, \"sanrentan\",np.append\\\n",
    "                                                                (preds_jiku[\"馬番\"].values, x), 1)).sum()\n",
    "                n_bets += len(preds_aite)\n",
    "                return_list.append(return_)\n",
    "            elif len(preds_jiku) >= 3:\n",
    "                return_ = 0\n",
    "                for umaban in permutations(preds_jiku[\"馬番\"], 3):\n",
    "                    return_ += self.bet(race_id, \"sanrentan\", umaban, 1)\n",
    "                    n_bets += 1\n",
    "                return_list.append(return_)\n",
    "                \n",
    "        std = np.std(return_list) * np.sqrt(len(return_list)) / n_bets\n",
    "        n_hits = np.sum([x>0 for x in return_list])\n",
    "        return_rate = np.sum(return_lsit) / n_bets\n",
    "        if items == True:\n",
    "            return {\"n_bets\":n_bets, \"return_rate\":return_rate, \"n_hits\":n_hits, \"std\":std}\n",
    "        else:\n",
    "            return n_bets, return_rate, n_hits, std\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79752988-5f07-4928-9e16-3ae2561ad16a",
   "metadata": {},
   "source": [
    "# Horse_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5e3ea8-f700-45f8-aea7-92ce02698f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Horse_Results:\n",
    "    def __init__(self, horse_results):\n",
    "        self.horse_results = horse_results[['日付','着順','賞金','着差','通過','開催','距離']]\n",
    "        self.preprocessing()\n",
    "        #self.horse_results.rename(columns={'着順':'着順_ave','賞金':'賞金_ave'}, inplace=True)\n",
    "    \n",
    "    # path_listはHorse_Results.pickle名\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        return cls(df)\n",
    "    # 使い方\n",
    "    # Horse_Results.read_pickle([pickle名])\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        #horse_idをkeyにしてDataFrame型を格納\n",
    "        horse_results = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            try:\n",
    "                url = 'https://db.netkeiba.com/horse/' + horse_id\n",
    "                df = pd.read_html(url)[3]\n",
    "                #受賞歴がある馬の場合、3番目に受賞歴テーブルが来るため、4番目のデータを取得する\n",
    "                if df.columns[0]=='受賞歴':\n",
    "                    df = pd.read_html(url)[4]\n",
    "                df.index = [horse_id] * len(df)\n",
    "                horse_results[horse_id] = df\n",
    "                time.sleep(1)\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        #pd.DataFrame型にして一つのデータにまとめる        \n",
    "        horse_results_df = pd.concat([horse_results[key] for key in horse_results])\n",
    "\n",
    "        return horse_results_df\n",
    "        \n",
    "        \n",
    "    def preprocessing(self):\n",
    "        df = self.horse_results.copy()\n",
    "\n",
    "        # 着順に数字以外の文字列が含まれているものを取り除く\n",
    "        df['着順'] = pd.to_numeric(df['着順'], errors='coerce')\n",
    "        df.dropna(subset=['着順'], inplace=True)\n",
    "        df['着順'] = df['着順'].astype(int)\n",
    "\n",
    "        df[\"date\"] = pd.to_datetime(df[\"日付\"])\n",
    "        df.drop(['日付'], axis=1, inplace=True)\n",
    "        \n",
    "        #賞金のNaNを0で埋める\n",
    "        df['賞金'].fillna(0, inplace=True)\n",
    "        \n",
    "        #1着の着差を0にする\n",
    "        df['着差'] = df['着差'].map(lambda x: 0 if x<0 else x)\n",
    "        \n",
    "        #レース展開データ\n",
    "        #n=1: 最初のコーナー位置, n=4: 最終コーナー位置\n",
    "        def corner(x, n):\n",
    "            if type(x) != str:\n",
    "                return x\n",
    "            elif n==4:\n",
    "                return int(re.findall(r'\\d+', x)[-1])\n",
    "            elif n==1:\n",
    "                return int(re.findall(r'\\d+', x)[0])\n",
    "        df['first_corner'] = df['通過'].map(lambda x: corner(x, 1))\n",
    "        df['final_corner'] = df['通過'].map(lambda x: corner(x, 4))\n",
    "        \n",
    "        df['final_to_rank'] = df['final_corner'] - df['着順']\n",
    "        df['first_to_rank'] = df['first_corner'] - df['着順']\n",
    "        df['first_to_final'] = df['first_corner'] - df['final_corner']\n",
    "        \n",
    "        #開催場所\n",
    "        df['開催'] = df['開催'].str.extract(r'(\\D+)')[0].map(place_dict).fillna('11')\n",
    "        #race_type\n",
    "        df['race_type'] = df['距離'].str.extract(r'(\\D+)')[0].map(race_type_dict)\n",
    "        #距離\n",
    "        df['course_len'] = df['距離'].str.extract(r'(\\d+)').astype(int) // 100\n",
    "        df.drop(['距離'], axis=1, inplace=True)\n",
    "        \n",
    "        #インデックス名を与える\n",
    "        df.index.name = 'horse_id'\n",
    "    \n",
    "        self.horse_results = df\n",
    "        self.target_list = ['着順', '賞金', '着差', 'first_corner',\n",
    "                            'first_to_rank', 'first_to_final','final_to_rank']\n",
    "        \n",
    "        \n",
    "    def average(self, horse_id_list, date, n_samples='all'):\n",
    "        target_df = self.horse_results.loc[horse_id_list]\n",
    "        \n",
    "        #過去何走分取り出すか指定\n",
    "        if n_samples == 'all':\n",
    "            filtered_df = target_df[target_df['date'] < date]\n",
    "        elif n_samples > 0:\n",
    "            filtered_df = target_df[target_df['date'] < date].\\\n",
    "                sort_values('date', ascending=False).groupby(level=0).head(n_samples)\n",
    "        else:\n",
    "            raise Exception('n_samples must be >0')\n",
    "          \n",
    "        self.average_dict = {}\n",
    "        self.average_dict['non_category'] = filtered_df.groupby(level=0)[self.target_list]\\\n",
    "            .mean().add_suffix('_{}R'.format(n_samples))\n",
    "        for column in ['course_len', 'race_type', '開催']:\n",
    "            self.average_dict[column] = filtered_df.groupby(['horse_id', column])\\\n",
    "                [self.target_list].mean().add_suffix('_{}_{}R'.format(column, n_samples))    \n",
    "    \n",
    "    def merge(self, results, date, n_samples='all'):\n",
    "        df = results[results['date']==date]\n",
    "        horse_id_list = df['horse_id']\n",
    "        self.average(horse_id_list, date, n_samples)\n",
    "        merged_df = df.merge(self.average_dict['non_category'], left_on='horse_id',\n",
    "                             right_index=True, how='left')\n",
    "        for column in ['course_len','race_type', '開催']:\n",
    "            merged_df = merged_df.merge(self.average_dict[column], \n",
    "                                        left_on=['horse_id', column],\n",
    "                                        right_index=True, how='left')\n",
    "        return merged_df\n",
    "    \n",
    "    def merge_all(self, results, n_samples='all'):\n",
    "        date_list = results['date'].unique()\n",
    "        merged_df = pd.concat(\n",
    "            [self.merge(results, date, n_samples) for date in tqdm(date_list)]\n",
    "        )\n",
    "        return merged_df\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d6c14-dae4-4ee2-9792-2c4de14c6a05",
   "metadata": {},
   "source": [
    "# Peds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028ca029-8035-4ef9-bade-ac428fe0bdae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Peds:\n",
    "    def __init__(self, peds):\n",
    "        self.peds = peds\n",
    "        self.peds_e = pd.DataFrame() #after label encoding and transforming into category\n",
    "    \n",
    "    def encode(self):\n",
    "        df = self.peds.copy()\n",
    "        for column in df.columns:\n",
    "            df[column] = LabelEncoder().fit_transform(df[column].fillna('Na'))\n",
    "        self.peds_e = df.astype('category')\n",
    "    \n",
    "    # Peds.read_pickle([\"pickle_path\"])\n",
    "    @classmethod\n",
    "    def read_pickle(cls, path_list):\n",
    "        df = pd.read_pickle(path_list[0])\n",
    "        for path in path_list[1:]:\n",
    "            df = update_data(df, pd.read_pickle(path))\n",
    "        return cls(df)\n",
    "        #df = pd.concat([pd.read_pickle(path) for path in path_list])\n",
    "        #return cls(df)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scrape(horse_id_list):\n",
    "        peds_dict = {}\n",
    "        for horse_id in tqdm(horse_id_list):\n",
    "            try:\n",
    "                url = \"https://db.netkeiba.com/horse/ped/\" + horse_id\n",
    "                df = pd.read_html(url)[0]\n",
    "                \n",
    "                #重複を削除して1列のSeries型データに直す\n",
    "                generations = {}\n",
    "                for i in reversed(range(5)):\n",
    "                    generations[i] = df[i]\n",
    "                    df.drop([i], axis = 1, inplace = True)\n",
    "                    df = df.drop_duplicates()\n",
    "                ped = pd.concat([generations[i] for i in range(5)]).rename(horse_id)\n",
    "                \n",
    "                peds_dict[horse_id] = ped.reset_index(drop = True)\n",
    "                time.sleep(0.7)\n",
    "                \n",
    "            except IndexError:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                break\n",
    "            except:\n",
    "                break\n",
    "        #return peds\n",
    "                \n",
    "        #列名をpeds_0, ..., peds_61にする\n",
    "        peds_df = pd.concat([peds_dict[key] for key in peds_dict], axis=1).T.add_prefix('peds_')\n",
    "    \n",
    "        return peds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6687d8-3042-4077-a07b-0ef20e6a37b6",
   "metadata": {},
   "source": [
    "# classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "b8e9c4a7-0e5f-45b4-ae51-f9997c22eae5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c6f6a77ba34e7b8a0314b094938688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163553e8b3474e3ba59ade58712fb3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a3c34efc3145bcbcb129d0d014410c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9400930505843544, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9400930505843544\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0\n"
     ]
    }
   ],
   "source": [
    "r = Results(results_all)\n",
    "r.preprocessing()\n",
    "hr = Horse_Results.read_pickle([\"horse_results_19.pickle\",\n",
    "                   'horse_results_20.pickle',\n",
    "                   'horse_results_21.pickle'])\n",
    "r.merge_horse_results(hr)\n",
    "P = Peds(n_peds_all2)\n",
    "P.encode()\n",
    "r.merge_peds(P.peds_e)\n",
    "r.process_categorical()\n",
    "\n",
    "X = r.data_c.drop([\"rank\",\"date\",\"単勝\"],axis=1)\n",
    "y = r.data_c[\"rank\"]\n",
    "\n",
    "train, test = split_data(r.data_c)\n",
    "train, valid = split_data(train)\n",
    "\n",
    "X_train = train.drop([\"rank\",\"date\",\"単勝\"],axis=1)\n",
    "y_train = train[\"rank\"]\n",
    "X_test = test.drop([\"rank\",\"date\",\"単勝\"],axis=1)\n",
    "y_test = test[\"rank\"]\n",
    "X_valid = valid.drop([\"rank\",\"date\",\"単勝\"],axis=1)\n",
    "y_valid = valid[\"rank\"]\n",
    "\n",
    "params = {\n",
    " 'objective': 'binary',\n",
    " 'random_state': 100,\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 0.0,\n",
    " 'lambda_l2': 0.0,\n",
    " 'num_leaves': 5,\n",
    " 'feature_fraction': 0.7,\n",
    " 'bagging_fraction': 0.9400930505843544,\n",
    " 'bagging_freq': 2,\n",
    " 'min_child_samples': 10}\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(**params)\n",
    "lgb_clf.fit(X.values, y.values)\n",
    "\n",
    "me = ModelEvaluator(lgb_clf, [\"Return_tables_all.pickle\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18433df1-acce-4168-a9f8-a21dc40c87fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-11 11:15:36,132]\u001b[0m A new study created in memory with name: no-name-5c9cdb0b-7c86-4d88-b3ca-1e3f59168c16\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                   | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.473292:  14%|8     | 1/7 [00:00<00:03,  1.76it/s]\u001b[32m[I 2022-01-11 11:15:36,707]\u001b[0m Trial 0 finished with value: 0.4732917691969007 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.4732917691969007.\u001b[0m\n",
      "feature_fraction, val_score: 0.473292:  14%|8     | 1/7 [00:00<00:03,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_logloss: 0.410017\tvalid_1's binary_logloss: 0.473292\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.472294:  29%|#7    | 2/7 [00:01<00:03,  1.44it/s]\u001b[32m[I 2022-01-11 11:15:37,490]\u001b[0m Trial 1 finished with value: 0.4722935446567878 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.4722935446567878.\u001b[0m\n",
      "feature_fraction, val_score: 0.472294:  29%|#7    | 2/7 [00:01<00:03,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's binary_logloss: 0.402\tvalid_1's binary_logloss: 0.472294\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.471358:  43%|##5   | 3/7 [00:01<00:02,  1.56it/s]\u001b[32m[I 2022-01-11 11:15:38,064]\u001b[0m Trial 2 finished with value: 0.4713577812741944 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.4713577812741944.\u001b[0m\n",
      "feature_fraction, val_score: 0.471358:  43%|##5   | 3/7 [00:01<00:02,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's binary_logloss: 0.396408\tvalid_1's binary_logloss: 0.471358\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.471358:  57%|###4  | 4/7 [00:02<00:02,  1.47it/s]\u001b[32m[I 2022-01-11 11:15:38,810]\u001b[0m Trial 3 finished with value: 0.47471837542355716 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.4713577812741944.\u001b[0m\n",
      "feature_fraction, val_score: 0.471358:  57%|###4  | 4/7 [00:02<00:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.397337\tvalid_1's binary_logloss: 0.474718\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.471358:  71%|####2 | 5/7 [00:03<00:01,  1.50it/s]\u001b[32m[I 2022-01-11 11:15:39,445]\u001b[0m Trial 4 finished with value: 0.4723921967484754 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.4713577812741944.\u001b[0m\n",
      "feature_fraction, val_score: 0.471358:  71%|####2 | 5/7 [00:03<00:01,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's binary_logloss: 0.382458\tvalid_1's binary_logloss: 0.472392\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.471358:  86%|#####1| 6/7 [00:04<00:00,  1.45it/s]\u001b[32m[I 2022-01-11 11:15:40,177]\u001b[0m Trial 5 finished with value: 0.47352727843955816 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.4713577812741944.\u001b[0m\n",
      "feature_fraction, val_score: 0.471358:  86%|#####1| 6/7 [00:04<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.388648\tvalid_1's binary_logloss: 0.473527\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.471358: 100%|######| 7/7 [00:04<00:00,  1.43it/s]\u001b[32m[I 2022-01-11 11:15:40,899]\u001b[0m Trial 6 finished with value: 0.4715243267953087 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.4713577812741944.\u001b[0m\n",
      "feature_fraction, val_score: 0.471358: 100%|######| 7/7 [00:04<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.382107\tvalid_1's binary_logloss: 0.471524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:   0%|                   | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:   5%|5          | 1/20 [00:00<00:16,  1.17it/s]\u001b[32m[I 2022-01-11 11:15:41,755]\u001b[0m Trial 7 finished with value: 0.47544294413915217 and parameters: {'num_leaves': 140}. Best is trial 7 with value: 0.47544294413915217.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:   5%|5          | 1/20 [00:00<00:16,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_logloss: 0.299331\tvalid_1's binary_logloss: 0.475443\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:  10%|#1         | 2/20 [00:01<00:13,  1.32it/s]\u001b[32m[I 2022-01-11 11:15:42,443]\u001b[0m Trial 8 finished with value: 0.47524363467029673 and parameters: {'num_leaves': 72}. Best is trial 8 with value: 0.47524363467029673.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:  10%|#1         | 2/20 [00:01<00:13,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's binary_logloss: 0.360561\tvalid_1's binary_logloss: 0.475244\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:  15%|#6         | 3/20 [00:02<00:12,  1.40it/s]\u001b[32m[I 2022-01-11 11:15:43,108]\u001b[0m Trial 9 finished with value: 0.47672334862552274 and parameters: {'num_leaves': 110}. Best is trial 8 with value: 0.47524363467029673.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:  15%|#6         | 3/20 [00:02<00:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's binary_logloss: 0.351029\tvalid_1's binary_logloss: 0.476723\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:  20%|##2        | 4/20 [00:03<00:12,  1.27it/s]\u001b[32m[I 2022-01-11 11:15:44,002]\u001b[0m Trial 10 finished with value: 0.48063501127287117 and parameters: {'num_leaves': 217}. Best is trial 8 with value: 0.47524363467029673.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:  20%|##2        | 4/20 [00:03<00:12,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's binary_logloss: 0.295642\tvalid_1's binary_logloss: 0.480635\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.452978\tvalid_1's binary_logloss: 0.474651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:  25%|##7        | 5/20 [00:03<00:10,  1.45it/s]\u001b[32m[I 2022-01-11 11:15:44,525]\u001b[0m Trial 11 finished with value: 0.4729866225621928 and parameters: {'num_leaves': 3}. Best is trial 11 with value: 0.4729866225621928.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:  25%|##7        | 5/20 [00:03<00:10,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's binary_logloss: 0.445358\tvalid_1's binary_logloss: 0.472987\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:  30%|###3       | 6/20 [00:04<00:08,  1.60it/s]\u001b[32m[I 2022-01-11 11:15:45,023]\u001b[0m Trial 12 finished with value: 0.471625114474602 and parameters: {'num_leaves': 33}. Best is trial 12 with value: 0.471625114474602.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:  30%|###3       | 6/20 [00:04<00:08,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.400417\tvalid_1's binary_logloss: 0.471625\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:  35%|###8       | 7/20 [00:05<00:10,  1.26it/s]\u001b[32m[I 2022-01-11 11:15:46,173]\u001b[0m Trial 13 finished with value: 0.47652584527199404 and parameters: {'num_leaves': 173}. Best is trial 12 with value: 0.471625114474602.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:  35%|###8       | 7/20 [00:05<00:10,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.259579\tvalid_1's binary_logloss: 0.476526\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471358:  40%|####4      | 8/20 [00:06<00:10,  1.12it/s]\u001b[32m[I 2022-01-11 11:15:47,278]\u001b[0m Trial 14 finished with value: 0.48046727848589643 and parameters: {'num_leaves': 212}. Best is trial 12 with value: 0.471625114474602.\u001b[0m\n",
      "num_leaves, val_score: 0.471358:  40%|####4      | 8/20 [00:06<00:10,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's binary_logloss: 0.293365\tvalid_1's binary_logloss: 0.480467\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  45%|####9      | 9/20 [00:06<00:08,  1.24it/s]\u001b[32m[I 2022-01-11 11:15:47,883]\u001b[0m Trial 15 finished with value: 0.4710818820073304 and parameters: {'num_leaves': 36}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  45%|####9      | 9/20 [00:06<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.391315\tvalid_1's binary_logloss: 0.471082\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  50%|#####     | 10/20 [00:07<00:08,  1.21it/s]\u001b[32m[I 2022-01-11 11:15:48,768]\u001b[0m Trial 16 finished with value: 0.4788682629311439 and parameters: {'num_leaves': 148}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  50%|#####     | 10/20 [00:07<00:08,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's binary_logloss: 0.288638\tvalid_1's binary_logloss: 0.478868\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  55%|#####5    | 11/20 [00:08<00:06,  1.32it/s]\u001b[32m[I 2022-01-11 11:15:49,369]\u001b[0m Trial 17 finished with value: 0.475950766366951 and parameters: {'num_leaves': 68}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  55%|#####5    | 11/20 [00:08<00:06,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's binary_logloss: 0.36876\tvalid_1's binary_logloss: 0.475951\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  60%|######    | 12/20 [00:08<00:05,  1.47it/s]\u001b[32m[I 2022-01-11 11:15:49,863]\u001b[0m Trial 18 finished with value: 0.4711451468478843 and parameters: {'num_leaves': 12}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  60%|######    | 12/20 [00:08<00:05,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's binary_logloss: 0.420052\tvalid_1's binary_logloss: 0.471145\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.460852\tvalid_1's binary_logloss: 0.47836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  65%|######5   | 13/20 [00:09<00:04,  1.56it/s]\u001b[32m[I 2022-01-11 11:15:50,422]\u001b[0m Trial 19 finished with value: 0.4746616102830887 and parameters: {'num_leaves': 2}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  65%|######5   | 13/20 [00:09<00:04,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's binary_logloss: 0.45459\tvalid_1's binary_logloss: 0.475219\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's binary_logloss: 0.452636\tvalid_1's binary_logloss: 0.474662\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  70%|#######   | 14/20 [00:10<00:03,  1.61it/s]\u001b[32m[I 2022-01-11 11:15:50,997]\u001b[0m Trial 20 finished with value: 0.47277821738930725 and parameters: {'num_leaves': 59}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  70%|#######   | 14/20 [00:10<00:03,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's binary_logloss: 0.371793\tvalid_1's binary_logloss: 0.472778\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  75%|#######5  | 15/20 [00:10<00:03,  1.49it/s]\u001b[32m[I 2022-01-11 11:15:51,781]\u001b[0m Trial 21 finished with value: 0.4750144252691115 and parameters: {'num_leaves': 107}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  75%|#######5  | 15/20 [00:10<00:03,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's binary_logloss: 0.311648\tvalid_1's binary_logloss: 0.475014\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  80%|########  | 16/20 [00:11<00:02,  1.60it/s]\u001b[32m[I 2022-01-11 11:15:52,293]\u001b[0m Trial 22 finished with value: 0.47253320005807803 and parameters: {'num_leaves': 37}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  80%|########  | 16/20 [00:11<00:02,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.395401\tvalid_1's binary_logloss: 0.472533\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  85%|########5 | 17/20 [00:11<00:01,  1.70it/s]\u001b[32m[I 2022-01-11 11:15:52,795]\u001b[0m Trial 23 finished with value: 0.471625114474602 and parameters: {'num_leaves': 33}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  85%|########5 | 17/20 [00:11<00:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.400417\tvalid_1's binary_logloss: 0.471625\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  90%|######### | 18/20 [00:12<00:01,  1.58it/s]\u001b[32m[I 2022-01-11 11:15:53,531]\u001b[0m Trial 24 finished with value: 0.4753050384423287 and parameters: {'num_leaves': 104}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  90%|######### | 18/20 [00:12<00:01,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's binary_logloss: 0.326786\tvalid_1's binary_logloss: 0.475305\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082:  95%|#########5| 19/20 [00:13<00:00,  1.56it/s]\u001b[32m[I 2022-01-11 11:15:54,195]\u001b[0m Trial 25 finished with value: 0.47551857047263363 and parameters: {'num_leaves': 84}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082:  95%|#########5| 19/20 [00:13<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's binary_logloss: 0.344082\tvalid_1's binary_logloss: 0.475519\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.471082: 100%|##########| 20/20 [00:14<00:00,  1.28it/s]\u001b[32m[I 2022-01-11 11:15:55,313]\u001b[0m Trial 26 finished with value: 0.4827594509275476 and parameters: {'num_leaves': 246}. Best is trial 15 with value: 0.4710818820073304.\u001b[0m\n",
      "num_leaves, val_score: 0.471082: 100%|##########| 20/20 [00:14<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's binary_logloss: 0.299755\tvalid_1's binary_logloss: 0.482759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:   0%|                      | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  10%|#4            | 1/10 [00:00<00:04,  1.83it/s]\u001b[32m[I 2022-01-11 11:15:55,863]\u001b[0m Trial 27 finished with value: 0.47439188573751767 and parameters: {'bagging_fraction': 0.7260429650751228, 'bagging_freq': 2}. Best is trial 27 with value: 0.47439188573751767.\u001b[0m\n",
      "bagging, val_score: 0.471082:  10%|#4            | 1/10 [00:00<00:04,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.385215\tvalid_1's binary_logloss: 0.474392\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008093 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  20%|##8           | 2/10 [00:01<00:04,  1.77it/s]\u001b[32m[I 2022-01-11 11:15:56,439]\u001b[0m Trial 28 finished with value: 0.47479160058971615 and parameters: {'bagging_fraction': 0.6547105544499044, 'bagging_freq': 6}. Best is trial 27 with value: 0.47439188573751767.\u001b[0m\n",
      "bagging, val_score: 0.471082:  20%|##8           | 2/10 [00:01<00:04,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.386048\tvalid_1's binary_logloss: 0.474792\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  30%|####2         | 3/10 [00:01<00:03,  1.99it/s]\u001b[32m[I 2022-01-11 11:15:56,870]\u001b[0m Trial 29 finished with value: 0.47895184770300814 and parameters: {'bagging_fraction': 0.4028313137145883, 'bagging_freq': 1}. Best is trial 27 with value: 0.47439188573751767.\u001b[0m\n",
      "bagging, val_score: 0.471082:  30%|####2         | 3/10 [00:01<00:03,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.412876\tvalid_1's binary_logloss: 0.478952\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  40%|#####6        | 4/10 [00:02<00:03,  1.85it/s]\u001b[32m[I 2022-01-11 11:15:57,466]\u001b[0m Trial 30 finished with value: 0.47363831579899873 and parameters: {'bagging_fraction': 0.802449450836738, 'bagging_freq': 6}. Best is trial 30 with value: 0.47363831579899873.\u001b[0m\n",
      "bagging, val_score: 0.471082:  40%|#####6        | 4/10 [00:02<00:03,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's binary_logloss: 0.376741\tvalid_1's binary_logloss: 0.473638\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  50%|#######       | 5/10 [00:02<00:02,  1.98it/s]\u001b[32m[I 2022-01-11 11:15:57,911]\u001b[0m Trial 31 finished with value: 0.479354701997597 and parameters: {'bagging_fraction': 0.4820239538111085, 'bagging_freq': 5}. Best is trial 30 with value: 0.47363831579899873.\u001b[0m\n",
      "bagging, val_score: 0.471082:  50%|#######       | 5/10 [00:02<00:02,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's binary_logloss: 0.407714\tvalid_1's binary_logloss: 0.479355\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  60%|########4     | 6/10 [00:03<00:02,  1.90it/s]\u001b[32m[I 2022-01-11 11:15:58,476]\u001b[0m Trial 32 finished with value: 0.4731338882006634 and parameters: {'bagging_fraction': 0.9347931725882498, 'bagging_freq': 2}. Best is trial 32 with value: 0.4731338882006634.\u001b[0m\n",
      "bagging, val_score: 0.471082:  60%|########4     | 6/10 [00:03<00:02,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's binary_logloss: 0.383109\tvalid_1's binary_logloss: 0.473134\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  70%|#########7    | 7/10 [00:03<00:01,  1.98it/s]\u001b[32m[I 2022-01-11 11:15:58,935]\u001b[0m Trial 33 finished with value: 0.47695567134924993 and parameters: {'bagging_fraction': 0.5111969317302304, 'bagging_freq': 1}. Best is trial 32 with value: 0.4731338882006634.\u001b[0m\n",
      "bagging, val_score: 0.471082:  70%|#########7    | 7/10 [00:03<00:01,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.403598\tvalid_1's binary_logloss: 0.476956\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011045 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  80%|###########2  | 8/10 [00:04<00:01,  1.95it/s]\u001b[32m[I 2022-01-11 11:15:59,464]\u001b[0m Trial 34 finished with value: 0.4750543134110979 and parameters: {'bagging_fraction': 0.531818495575215, 'bagging_freq': 7}. Best is trial 32 with value: 0.4731338882006634.\u001b[0m\n",
      "bagging, val_score: 0.471082:  80%|###########2  | 8/10 [00:04<00:01,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's binary_logloss: 0.386845\tvalid_1's binary_logloss: 0.475054\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082:  90%|############6 | 9/10 [00:04<00:00,  1.92it/s]\u001b[32m[I 2022-01-11 11:16:00,001]\u001b[0m Trial 35 finished with value: 0.47226067041864694 and parameters: {'bagging_fraction': 0.8870098894544057, 'bagging_freq': 2}. Best is trial 35 with value: 0.47226067041864694.\u001b[0m\n",
      "bagging, val_score: 0.471082:  90%|############6 | 9/10 [00:04<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.389293\tvalid_1's binary_logloss: 0.472261\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.471082: 100%|#############| 10/10 [00:05<00:00,  1.78it/s]\u001b[32m[I 2022-01-11 11:16:00,656]\u001b[0m Trial 36 finished with value: 0.472901547078201 and parameters: {'bagging_fraction': 0.8897348492363203, 'bagging_freq': 2}. Best is trial 35 with value: 0.47226067041864694.\u001b[0m\n",
      "bagging, val_score: 0.471082: 100%|#############| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's binary_logloss: 0.358799\tvalid_1's binary_logloss: 0.472902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.471082:   0%|       | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.471082:  33%|3| 1/3 [00:00<00:00,  2.07it/\u001b[32m[I 2022-01-11 11:16:01,142]\u001b[0m Trial 37 finished with value: 0.4731739047036417 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.4731739047036417.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.471082:  33%|3| 1/3 [00:00<00:00,  2.07it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.407936\tvalid_1's binary_logloss: 0.473174\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.471082:  67%|6| 2/3 [00:01<00:00,  1.66it/\u001b[32m[I 2022-01-11 11:16:01,830]\u001b[0m Trial 38 finished with value: 0.47240962875453635 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.47240962875453635.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.471082:  67%|6| 2/3 [00:01<00:00,  1.66it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's binary_logloss: 0.39468\tvalid_1's binary_logloss: 0.47241\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.471082: 100%|#| 3/3 [00:01<00:00,  1.64it/\u001b[32m[I 2022-01-11 11:16:02,445]\u001b[0m Trial 39 finished with value: 0.4725098110509399 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 38 with value: 0.47240962875453635.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.471082: 100%|#| 3/3 [00:01<00:00,  1.68it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.40054\tvalid_1's binary_logloss: 0.47251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:   0%|       | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:   5%| | 1/20 [00:00<00:11,  1.65it/\u001b[32m[I 2022-01-11 11:16:03,053]\u001b[0m Trial 40 finished with value: 0.47108179320484433 and parameters: {'lambda_l1': 0.0007773998922821829, 'lambda_l2': 3.2012859298995277e-06}. Best is trial 40 with value: 0.47108179320484433.\u001b[0m\n",
      "regularization_factors, val_score: 0.471082:   5%| | 1/20 [00:00<00:11,  1.65it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.391318\tvalid_1's binary_logloss: 0.471082\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:  10%|1| 2/20 [00:01<00:12,  1.49it/\u001b[32m[I 2022-01-11 11:16:03,769]\u001b[0m Trial 41 finished with value: 0.47257368163706215 and parameters: {'lambda_l1': 6.616957066014342e-05, 'lambda_l2': 0.400853048601546}. Best is trial 40 with value: 0.47108179320484433.\u001b[0m\n",
      "regularization_factors, val_score: 0.471082:  10%|1| 2/20 [00:01<00:12,  1.49it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's binary_logloss: 0.38643\tvalid_1's binary_logloss: 0.472574\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:  15%|1| 3/20 [00:01<00:10,  1.60it/\u001b[32m[I 2022-01-11 11:16:04,341]\u001b[0m Trial 42 finished with value: 0.47108188197838413 and parameters: {'lambda_l1': 1.1027313099672533e-08, 'lambda_l2': 1.242001404761155e-07}. Best is trial 40 with value: 0.47108179320484433.\u001b[0m\n",
      "regularization_factors, val_score: 0.471082:  15%|1| 3/20 [00:01<00:10,  1.60it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.391315\tvalid_1's binary_logloss: 0.471082\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:  20%|2| 4/20 [00:02<00:10,  1.54it/\u001b[32m[I 2022-01-11 11:16:05,030]\u001b[0m Trial 43 finished with value: 0.4724267216485891 and parameters: {'lambda_l1': 0.010882827930218712, 'lambda_l2': 0.2708162972907513}. Best is trial 40 with value: 0.47108179320484433.\u001b[0m\n",
      "regularization_factors, val_score: 0.471082:  20%|2| 4/20 [00:02<00:10,  1.54it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's binary_logloss: 0.371384\tvalid_1's binary_logloss: 0.472427\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:  25%|2| 5/20 [00:03<00:09,  1.64it/\u001b[32m[I 2022-01-11 11:16:05,570]\u001b[0m Trial 44 finished with value: 0.4714968168480523 and parameters: {'lambda_l1': 1.6996492507894156e-07, 'lambda_l2': 0.0014991323116035308}. Best is trial 40 with value: 0.47108179320484433.\u001b[0m\n",
      "regularization_factors, val_score: 0.471082:  25%|2| 5/20 [00:03<00:09,  1.64it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.400856\tvalid_1's binary_logloss: 0.471497\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:  30%|3| 6/20 [00:03<00:08,  1.67it/\u001b[32m[I 2022-01-11 11:16:06,148]\u001b[0m Trial 45 finished with value: 0.4720210313506172 and parameters: {'lambda_l1': 1.0517138394360073, 'lambda_l2': 7.635176818135586e-07}. Best is trial 40 with value: 0.47108179320484433.\u001b[0m\n",
      "regularization_factors, val_score: 0.471082:  30%|3| 6/20 [00:03<00:08,  1.67it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.39921\tvalid_1's binary_logloss: 0.472021\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.471082:  35%|3| 7/20 [00:04<00:07,  1.68it/\u001b[32m[I 2022-01-11 11:16:06,733]\u001b[0m Trial 46 finished with value: 0.4710818819280507 and parameters: {'lambda_l1': 4.655367559816141e-07, 'lambda_l2': 9.449134137745608e-08}. Best is trial 40 with value: 0.47108179320484433.\u001b[0m\n",
      "regularization_factors, val_score: 0.471082:  35%|3| 7/20 [00:04<00:07,  1.68it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.391315\tvalid_1's binary_logloss: 0.471082\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  40%|4| 8/20 [00:05<00:07,  1.54it/\u001b[32m[I 2022-01-11 11:16:07,495]\u001b[0m Trial 47 finished with value: 0.4704622965767679 and parameters: {'lambda_l1': 9.490245203532942e-07, 'lambda_l2': 6.421168438428032}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  40%|4| 8/20 [00:05<00:07,  1.54it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.378342\tvalid_1's binary_logloss: 0.470462\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  45%|4| 9/20 [00:05<00:07,  1.55it/\u001b[32m[I 2022-01-11 11:16:08,138]\u001b[0m Trial 48 finished with value: 0.47281908420246005 and parameters: {'lambda_l1': 0.2019055894080857, 'lambda_l2': 3.5275169933928286e-07}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  45%|4| 9/20 [00:05<00:07,  1.55it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.379185\tvalid_1's binary_logloss: 0.472819\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  50%|5| 10/20 [00:06<00:06,  1.61it\u001b[32m[I 2022-01-11 11:16:08,697]\u001b[0m Trial 49 finished with value: 0.47280199926184313 and parameters: {'lambda_l1': 0.22183125618514202, 'lambda_l2': 2.9286247167445133e-06}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  50%|5| 10/20 [00:06<00:06,  1.61it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.400325\tvalid_1's binary_logloss: 0.472802\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  55%|5| 11/20 [00:06<00:05,  1.63it\u001b[32m[I 2022-01-11 11:16:09,299]\u001b[0m Trial 50 finished with value: 0.4723364380680939 and parameters: {'lambda_l1': 3.005784364160781e-05, 'lambda_l2': 8.382977103422135}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  55%|5| 11/20 [00:06<00:05,  1.63it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.407383\tvalid_1's binary_logloss: 0.472336\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  60%|6| 12/20 [00:07<00:04,  1.69it\u001b[32m[I 2022-01-11 11:16:09,838]\u001b[0m Trial 51 finished with value: 0.47147653487683644 and parameters: {'lambda_l1': 0.001629615110633885, 'lambda_l2': 0.00010206798630095434}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  60%|6| 12/20 [00:07<00:04,  1.69it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.400855\tvalid_1's binary_logloss: 0.471477\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  65%|6| 13/20 [00:07<00:04,  1.70it\u001b[32m[I 2022-01-11 11:16:10,421]\u001b[0m Trial 52 finished with value: 0.47108548530964045 and parameters: {'lambda_l1': 4.2209347477110245e-06, 'lambda_l2': 0.0001393059276291125}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  65%|6| 13/20 [00:07<00:04,  1.70it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.391316\tvalid_1's binary_logloss: 0.471085\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  70%|7| 14/20 [00:08<00:03,  1.73it\u001b[32m[I 2022-01-11 11:16:10,973]\u001b[0m Trial 53 finished with value: 0.4716712583840875 and parameters: {'lambda_l1': 0.0007036107746751689, 'lambda_l2': 0.002056226439492475}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  70%|7| 14/20 [00:08<00:03,  1.73it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.400863\tvalid_1's binary_logloss: 0.471671\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  75%|7| 15/20 [00:09<00:02,  1.76it\u001b[32m[I 2022-01-11 11:16:11,520]\u001b[0m Trial 54 finished with value: 0.4716731594764533 and parameters: {'lambda_l1': 0.008150367242200085, 'lambda_l2': 1.2058551574185216e-05}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  75%|7| 15/20 [00:09<00:02,  1.76it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.400875\tvalid_1's binary_logloss: 0.471673\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  80%|8| 16/20 [00:09<00:02,  1.75it\u001b[32m[I 2022-01-11 11:16:12,096]\u001b[0m Trial 55 finished with value: 0.47108188110989596 and parameters: {'lambda_l1': 7.739628356000219e-06, 'lambda_l2': 1.220872659800592e-08}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  80%|8| 16/20 [00:09<00:02,  1.75it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.391315\tvalid_1's binary_logloss: 0.471082\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  85%|8| 17/20 [00:10<00:01,  1.74it\u001b[32m[I 2022-01-11 11:16:12,681]\u001b[0m Trial 56 finished with value: 0.4720365665267894 and parameters: {'lambda_l1': 8.60829308495618e-07, 'lambda_l2': 0.024953769574992637}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  85%|8| 17/20 [00:10<00:01,  1.74it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.390462\tvalid_1's binary_logloss: 0.472037\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  90%|9| 18/20 [00:10<00:01,  1.73it\u001b[32m[I 2022-01-11 11:16:13,266]\u001b[0m Trial 57 finished with value: 0.4710977935736477 and parameters: {'lambda_l1': 1.5715715986416624e-08, 'lambda_l2': 1.4742611347943759e-05}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  90%|9| 18/20 [00:10<00:01,  1.73it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.391315\tvalid_1's binary_logloss: 0.471098\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462:  95%|9| 19/20 [00:11<00:00,  1.67it\u001b[32m[I 2022-01-11 11:16:13,918]\u001b[0m Trial 58 finished with value: 0.4716079815230466 and parameters: {'lambda_l1': 0.0001266013642214729, 'lambda_l2': 0.015296489547985315}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462:  95%|9| 19/20 [00:11<00:00,  1.67it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.375798\tvalid_1's binary_logloss: 0.471608\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.470462: 100%|#| 20/20 [00:12<00:00,  1.68it\u001b[32m[I 2022-01-11 11:16:14,503]\u001b[0m Trial 59 finished with value: 0.47109624438133857 and parameters: {'lambda_l1': 0.007924888721275036, 'lambda_l2': 3.633206895980047}. Best is trial 47 with value: 0.4704622965767679.\u001b[0m\n",
      "regularization_factors, val_score: 0.470462: 100%|#| 20/20 [00:12<00:00,  1.66it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's binary_logloss: 0.404706\tvalid_1's binary_logloss: 0.471096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.470462:   0%|              | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.470339:  20%|#2    | 1/5 [00:00<00:03,  1.23it/s]\u001b[32m[I 2022-01-11 11:16:15,321]\u001b[0m Trial 60 finished with value: 0.47033947726439296 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.47033947726439296.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.470339:  20%|#2    | 1/5 [00:00<00:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's binary_logloss: 0.387542\tvalid_1's binary_logloss: 0.470339\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.469552:  40%|##4   | 2/5 [00:01<00:02,  1.19it/s]\u001b[32m[I 2022-01-11 11:16:16,184]\u001b[0m Trial 61 finished with value: 0.46955217866906734 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 0.46955217866906734.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.469552:  40%|##4   | 2/5 [00:01<00:02,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.370755\tvalid_1's binary_logloss: 0.469552\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.469552:  60%|###6  | 3/5 [00:02<00:01,  1.31it/s]\u001b[32m[I 2022-01-11 11:16:16,858]\u001b[0m Trial 62 finished with value: 0.4700263857089038 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.46955217866906734.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.469552:  60%|###6  | 3/5 [00:02<00:01,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.388514\tvalid_1's binary_logloss: 0.470026\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.469552:  80%|####8 | 4/5 [00:03<00:00,  1.38it/s]\u001b[32m[I 2022-01-11 11:16:17,519]\u001b[0m Trial 63 finished with value: 0.47240758043705433 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 0.46955217866906734.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.469552:  80%|####8 | 4/5 [00:03<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's binary_logloss: 0.40175\tvalid_1's binary_logloss: 0.472408\n",
      "[LightGBM] [Info] Number of positive: 5074, number of negative: 18345\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29760\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216662 -> initscore=-1.285228\n",
      "[LightGBM] [Info] Start training from score -1.285228\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.469552: 100%|######| 5/5 [00:03<00:00,  1.30it/s]\u001b[32m[I 2022-01-11 11:16:18,369]\u001b[0m Trial 64 finished with value: 0.46955217866906734 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.46955217866906734.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.469552: 100%|######| 5/5 [00:03<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's binary_logloss: 0.370755\tvalid_1's binary_logloss: 0.469552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb_o.Dataset(X_train.values, y_train.values)\n",
    "lgb_valid = lgb_o.Dataset(X_valid.values, y_valid.values)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary', #今回は0or1の二値予測なのでbinaryを指定\n",
    "    'random_state': 100\n",
    "}\n",
    "\n",
    "#チューニング実行\n",
    "lgb_clf_o = lgb_o.train(params, lgb_train,\n",
    "                        valid_sets=(lgb_train, lgb_valid),\n",
    "                        verbose_eval=100,\n",
    "                        early_stopping_rounds=10,\n",
    "                        optuna_seed=100 #optunaのseed固定\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "7fb0c483-f1f9-44c7-9abf-5d8abad9c6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>date</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>10614</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>114.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>8270</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>10194</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>9851</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>9967</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>6372</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>3782</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>3136</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>3495</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>3331</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47118 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              着順  枠番  馬番    斤量     単勝  course_len       date horse_id  \\\n",
       "201901010101   1   1   1  54.0    1.4        18.0 2019-07-27    10614   \n",
       "201901010101   7   2   2  54.0  114.7        18.0 2019-07-27     8270   \n",
       "201901010101   2   3   3  54.0    3.5        18.0 2019-07-27    10194   \n",
       "201901010101   3   4   4  51.0   46.6        18.0 2019-07-27     9851   \n",
       "201901010101   5   5   5  54.0  140.3        18.0 2019-07-27     9967   \n",
       "...           ..  ..  ..   ...    ...         ...        ...      ...   \n",
       "201910021212  15   6  12  52.0   17.5        26.0 2019-09-01     6372   \n",
       "201910021212   5   7  13  57.0    7.7        26.0 2019-09-01     3782   \n",
       "201910021212   1   7  14  57.0    4.4        26.0 2019-09-01     3136   \n",
       "201910021212   3   8  15  57.0   21.9        26.0 2019-09-01     3495   \n",
       "201910021212  11   8  16  55.0   15.1        26.0 2019-09-01     3331   \n",
       "\n",
       "             jockey_id  rank  ...  race_type_芝  race_type_ダート  race_type_障害  \\\n",
       "201901010101       152     1  ...            1              0             0   \n",
       "201901010101        73     0  ...            1              0             0   \n",
       "201901010101       142     1  ...            1              0             0   \n",
       "201901010101       136     1  ...            1              0             0   \n",
       "201901010101        47     0  ...            1              0             0   \n",
       "...                ...   ...  ...          ...            ...           ...   \n",
       "201910021212         5     0  ...            1              0             0   \n",
       "201910021212        28     0  ...            1              0             0   \n",
       "201910021212        77     1  ...            1              0             0   \n",
       "201910021212        87     1  ...            1              0             0   \n",
       "201910021212        27     0  ...            1              0             0   \n",
       "\n",
       "              ground_state_良  ground_state_不良  ground_state_稍重  \\\n",
       "201901010101               1                0                0   \n",
       "201901010101               1                0                0   \n",
       "201901010101               1                0                0   \n",
       "201901010101               1                0                0   \n",
       "201901010101               1                0                0   \n",
       "...                      ...              ...              ...   \n",
       "201910021212               0                0                0   \n",
       "201910021212               0                0                0   \n",
       "201910021212               0                0                0   \n",
       "201910021212               0                0                0   \n",
       "201910021212               0                0                0   \n",
       "\n",
       "              ground_state_重  性_牡  性_牝  性_セ  \n",
       "201901010101               0    1    0    0  \n",
       "201901010101               0    0    1    0  \n",
       "201901010101               0    1    0    0  \n",
       "201901010101               0    1    0    0  \n",
       "201901010101               0    1    0    0  \n",
       "...                      ...  ...  ...  ...  \n",
       "201910021212               1    0    1    0  \n",
       "201910021212               1    1    0    0  \n",
       "201910021212               1    1    0    0  \n",
       "201910021212               1    1    0    0  \n",
       "201910021212               1    0    1    0  \n",
       "\n",
       "[47118 rows x 178 columns]"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18aba953-bf87-4a81-b623-63c167547f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_iterations = lgb_clf_o.params.pop('num_iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f25b878f-019b-4cb0-b2fb-96e338e1c088",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cdd06eb7bdd43e79a9922f113b8360b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f245db507e6a4a5688b9be79199cbebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea0e462016c48cf8a475b3442f57853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67751c654c8e4274a28870baf98d7cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>馬番</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>10</td>\n",
       "      <td>1.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>7</td>\n",
       "      <td>1.770203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>9</td>\n",
       "      <td>1.241675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>13</td>\n",
       "      <td>0.578290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>2</td>\n",
       "      <td>0.553096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>16</td>\n",
       "      <td>0.508320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>6</td>\n",
       "      <td>0.088539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.223722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.392259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>11</td>\n",
       "      <td>-0.455141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.692501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.806649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.897429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>14</td>\n",
       "      <td>-0.930354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.974901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106050811</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.273417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              馬番     score\n",
       "202106050811  10  1.906250\n",
       "202106050811   7  1.770203\n",
       "202106050811   9  1.241675\n",
       "202106050811  13  0.578290\n",
       "202106050811   2  0.553096\n",
       "202106050811  16  0.508320\n",
       "202106050811   6  0.088539\n",
       "202106050811  12 -0.223722\n",
       "202106050811   5 -0.392259\n",
       "202106050811  11 -0.455141\n",
       "202106050811   1 -0.692501\n",
       "202106050811  15 -0.806649\n",
       "202106050811   8 -0.897429\n",
       "202106050811  14 -0.930354\n",
       "202106050811   3 -0.974901\n",
       "202106050811   4 -1.273417"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf = lgb.LGBMClassifier(**new_params)\n",
    "lgb_clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "race_id = [\"202106050811\"]\n",
    "st = ShutubaTable.scrape(race_id, \"2021/12/26\")\n",
    "\n",
    "st.preprocessing()\n",
    "st.merge_horse_results(hr)\n",
    "st.merge_peds(P.peds_e)\n",
    "st.process_categorical(r.le_horse, r.le_jockey, r.data_pe)\n",
    "\n",
    "me = ModelEvaluator(lgb_clf,[\"Return_tables_all.pickle\"])\n",
    "\n",
    "\n",
    "scores = me.predict_proba(st.data_c.drop(['date'], axis=1), train=False)\n",
    "pred = st.data_c[['馬番']].copy()\n",
    "pred['score'] = scores\n",
    "pred.loc['202106050811'].sort_values('score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65446093-2c32-4356-bce2-b69bb6ffe956",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df6d4994b4f4e9a80f1f834e345f3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe524fb06d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train2, test2 = split_data(r.data_c)\n",
    "X_train2 = train2.drop([\"rank\",\"date\"],axis=1).copy()\n",
    "y_train2 = train2[\"rank\"]\n",
    "\n",
    "return_ = gain(me.tansho_return,X_train2)\n",
    "plt.figure(dpi=100)\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('return_rate')\n",
    "plt.fill_between(return_.index, y1 = (return_[\"return_rate\"] - return_[\"std\"]),\n",
    "                                 y2 = (return_[\"return_rate\"] + return_[\"std\"]),alpha=0.3)\n",
    "return_rate = plt.plot(return_.index, return_[\"return_rate\"], label=\"tansho_return\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4604897-eea0-42bb-a1e7-b86d8a6d6aaa",
   "metadata": {},
   "source": [
    "# ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dc7ff7cc-a4dd-4b1b-84e2-ec6ba8df5e83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_query = train.groupby(level=0)['馬番'].count()\n",
    "test_query = test.groupby(level=0)['馬番'].count()\n",
    "\n",
    "params = {\n",
    " 'objective': 'lambdarank',\n",
    " 'metrics': \"ndcg\",\n",
    " \"ndcg_eval_at\" : [1,3,5],\n",
    " \"boosting_type\" : \"gbdt\",\n",
    "}\n",
    "\n",
    "#model = lgb.train(params, train_query, valid_sets=test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b507e00-eed5-4bee-a812-dbed7fa746b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Training only accepts Dataset object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/fn98hw1541vg9yshhxdqfgc80000gn/T/ipykernel_42740/352669477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m }\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# check dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training only accepts Dataset object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Training only accepts Dataset object"
     ]
    }
   ],
   "source": [
    "train_q = [train_query[i] for i in range(len(train_query))]\n",
    "test_q = [test_query[i] for i in range(len(test_query))]\n",
    "\n",
    "params = {\n",
    " 'objective': 'lambdarank',\n",
    " 'metrics': \"ndcg\",\n",
    " \"ndcg_eval_at\" : [1,3,5],\n",
    " \"boosting_type\" : \"gbdt\",\n",
    "}\n",
    "\n",
    "model = lgb.train(params, train_q, valid_sets=test_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "02e4e5ff-c81b-4475-bab9-25c056a5bff0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 54594\n",
      "[LightGBM] [Info] Number of data points in the train set: 23419, number of used features: 172\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[52]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[53]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[54]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[55]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[56]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[57]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[58]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[59]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[60]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[61]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[62]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[63]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[64]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[65]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[66]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[67]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[68]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[69]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[70]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[71]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[72]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[73]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[74]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[75]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[76]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[77]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[78]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[79]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[80]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[81]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[82]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[83]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[84]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[85]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[86]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[87]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[88]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[89]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[90]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[91]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[92]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[93]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[94]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[95]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[96]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[97]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[98]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[99]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[100]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@5: 1\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(train.drop('date', axis=1), group=train_query)\n",
    "dval = lgb.Dataset(test.drop('date', axis=1), reference=dtrain, group=test_query)\n",
    "moodel = lgb.train(params, dtrain, valid_sets=dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "28bcbd7e-994d-4833-8840-2bbff9afd1e8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = moodel.predict(test.drop('date',axis=1), num_iteration=moodel.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6bdd201c-d9f2-4262-9ce3-c4d6639de470",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'value_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/fn98hw1541vg9yshhxdqfgc80000gn/T/ipykernel_42740/3768871735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'value_counts'"
     ]
    }
   ],
   "source": [
    "pred.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7e9a3a-0a47-43e8-91e4-bc5b098de6b4",
   "metadata": {},
   "source": [
    "# regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "261578bf-6078-4e02-8cfe-40459b18b253",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "進捗　\n",
    "random forset regressorで学習を行った。\n",
    "score(R^2)が0.44であった。\n",
    "adjusted_r2_score0.44\n",
    "\n",
    "\n",
    "\n",
    "目的　scoreの値を小数点第二位まで正確に求める。\n",
    "方法　特徴量の追加、paramsの設定\n",
    "\n",
    "regression用のモデル検証関数の作成する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "65e86b5a-5bfb-49a2-a52a-86be42475b7f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "import sklearn.ensemble as ske\n",
    "rf = ske.RandomForestRegressor()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "f863f932-45f8-479b-a9b4-d3aeb9eacefa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gridserch用のparams\n",
    "parameters = {\n",
    "    \"n_estimators\" : [10,20,30,50,100],\n",
    "    \"max_features\" : ('sqrt', 'log2','auto', None),\n",
    "    \"max_depth\" : (10,20,30,40,50,None),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92729f-d68a-4ab5-9cca-57a4496b3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassifierではlightGBM(ブースティング手法)を利用して分析を行なった。\n",
    "RegressorではRandom Forest regressor(バギング手法)を利用して分析を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "301b78a8-db92-4039-a3fa-b1cd895e746a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d74281563b4194b02fa8536f4d94f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae6caac05534ef89d94c382ab994099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6d7e37a23a49abb494f6e75b60acee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "r = Results(results_all)\n",
    "r.preprocessing(regression=True) \n",
    "#columnにタイム(走破時間を秒数に直したものとタイムをrootとlogをとったものを追加)\n",
    "hr = Horse_Results.read_pickle([\"horse_results_19.pickle\",\n",
    "                   'horse_results_20.pickle',\n",
    "                   'horse_results_21.pickle'])\n",
    "r.merge_horse_results(hr)\n",
    "P = Peds(n_peds_all2)\n",
    "P.encode()\n",
    "r.merge_peds(P.peds_e)\n",
    "r.process_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "648fedc9-ee83-42fd-8f1c-a5b0a27ae47b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#使用していない\n",
    "train, test = split_data(r.data_p)\n",
    "X = r.data_c.drop([\"date\",\"rank\"], axis=1)\n",
    "y = r.data_c[\"rls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a97e72-82f9-41c6-b2a1-74b453493fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "4682020b-2079-4784-bf2e-1b8f8133a42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#regressionで使用するX,y\n",
    "X = r.data_p.dropna(axis=1).drop([\"rls\",\"rank\",\"second\",\"着順\",\"単勝\"],axis=1)\n",
    "y = r.data_p[\"rls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "13ce1b78-755a-42fc-ac68-0f8e6f0a9b65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>ground_state</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>性</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>体重変化</th>\n",
       "      <th>second</th>\n",
       "      <th>rls</th>\n",
       "      <th>開催</th>\n",
       "      <th>n_horses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>05339</td>\n",
       "      <td>1</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>518</td>\n",
       "      <td>-16</td>\n",
       "      <td>156.3</td>\n",
       "      <td>2.247616</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>05203</td>\n",
       "      <td>1</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>496</td>\n",
       "      <td>-8</td>\n",
       "      <td>160.1</td>\n",
       "      <td>2.252953</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>01180</td>\n",
       "      <td>1</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>546</td>\n",
       "      <td>6</td>\n",
       "      <td>160.9</td>\n",
       "      <td>2.254059</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>01179</td>\n",
       "      <td>0</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>458</td>\n",
       "      <td>-8</td>\n",
       "      <td>162.5</td>\n",
       "      <td>2.256253</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>01062</td>\n",
       "      <td>0</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "      <td>162.7</td>\n",
       "      <td>2.256526</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>56.0</td>\n",
       "      <td>120.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>01165</td>\n",
       "      <td>0</td>\n",
       "      <td>セ</td>\n",
       "      <td>6</td>\n",
       "      <td>458</td>\n",
       "      <td>8</td>\n",
       "      <td>210.7</td>\n",
       "      <td>2.313101</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>01178</td>\n",
       "      <td>0</td>\n",
       "      <td>牡</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>2</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.314430</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>01176</td>\n",
       "      <td>0</td>\n",
       "      <td>牡</td>\n",
       "      <td>4</td>\n",
       "      <td>478</td>\n",
       "      <td>14</td>\n",
       "      <td>212.2</td>\n",
       "      <td>2.314634</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>00666</td>\n",
       "      <td>0</td>\n",
       "      <td>牝</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>2</td>\n",
       "      <td>212.2</td>\n",
       "      <td>2.314634</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>...</td>\n",
       "      <td>01128</td>\n",
       "      <td>0</td>\n",
       "      <td>牝</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>8</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2.316458</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47118 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              着順  枠番  馬番    斤量     単勝  course_len weather race_type  \\\n",
       "201901010101   1   1   1  54.0    1.4        18.0       曇         芝   \n",
       "201901010101   2   3   3  54.0    3.5        18.0       曇         芝   \n",
       "201901010101   3   4   4  51.0   46.6        18.0       曇         芝   \n",
       "201901010101   4   8   9  51.0   56.8        18.0       曇         芝   \n",
       "201901010101   5   5   5  54.0  140.3        18.0       曇         芝   \n",
       "...           ..  ..  ..   ...    ...         ...     ...       ...   \n",
       "201910021212  12   6  11  56.0  120.3        26.0       曇         芝   \n",
       "201910021212  13   1   1  54.0    7.5        26.0       曇         芝   \n",
       "201910021212  14   2   3  54.0   99.2        26.0       曇         芝   \n",
       "201910021212  15   6  12  52.0   17.5        26.0       曇         芝   \n",
       "201910021212  16   2   4  55.0  110.3        26.0       曇         芝   \n",
       "\n",
       "             ground_state       date  ... jockey_id rank  性 年齢   体重  体重変化  \\\n",
       "201901010101            良 2019-07-27  ...     05339    1  牡  2  518   -16   \n",
       "201901010101            良 2019-07-27  ...     05203    1  牡  2  496    -8   \n",
       "201901010101            良 2019-07-27  ...     01180    1  牡  2  546     6   \n",
       "201901010101            良 2019-07-27  ...     01179    0  牡  2  458    -8   \n",
       "201901010101            良 2019-07-27  ...     01062    0  牡  2  436     0   \n",
       "...                   ...        ...  ...       ...  ... .. ..  ...   ...   \n",
       "201910021212            重 2019-09-01  ...     01165    0  セ  6  458     8   \n",
       "201910021212            重 2019-09-01  ...     01178    0  牡  5  460     2   \n",
       "201910021212            重 2019-09-01  ...     01176    0  牡  4  478    14   \n",
       "201910021212            重 2019-09-01  ...     00666    0  牝  3  468     2   \n",
       "201910021212            重 2019-09-01  ...     01128    0  牝  4  450     8   \n",
       "\n",
       "              second       rls  開催 n_horses  \n",
       "201901010101   156.3  2.247616  01        9  \n",
       "201901010101   160.1  2.252953  01        9  \n",
       "201901010101   160.9  2.254059  01        9  \n",
       "201901010101   162.5  2.256253  01        9  \n",
       "201901010101   162.7  2.256526  01        9  \n",
       "...              ...       ...  ..      ...  \n",
       "201910021212   210.7  2.313101  10       16  \n",
       "201910021212   212.0  2.314430  10       16  \n",
       "201910021212   212.2  2.314634  10       16  \n",
       "201910021212   212.2  2.314634  10       16  \n",
       "201910021212   214.0  2.316458  10       16  \n",
       "\n",
       "[47118 rows x 21 columns]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#現在の特徴量\n",
    "r.data_p.dropna()\n",
    "#dropnaしたものに、horse_resultsをマージして、fillna = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "261d896f-fdf8-47a6-9777-56a9cf2ab949",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>ground_state</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>first_to_rank_race_type_allR</th>\n",
       "      <th>first_to_final_race_type_allR</th>\n",
       "      <th>final_to_rank_race_type_allR</th>\n",
       "      <th>着順_開催_allR</th>\n",
       "      <th>賞金_開催_allR</th>\n",
       "      <th>着差_開催_allR</th>\n",
       "      <th>first_corner_開催_allR</th>\n",
       "      <th>first_to_rank_開催_allR</th>\n",
       "      <th>first_to_final_開催_allR</th>\n",
       "      <th>final_to_rank_開催_allR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2019-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908040412</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>57.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>ダート</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.055556</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-3.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1535.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908040412</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>ダート</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.536585</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>1.365854</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>165.093750</td>\n",
       "      <td>1.081250</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908040412</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>ダート</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.722222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>438.311111</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>1.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908040412</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>ダート</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-2.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>267.075000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-2.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908040412</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>晴</td>\n",
       "      <td>ダート</td>\n",
       "      <td>重</td>\n",
       "      <td>2019-10-13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47118 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              着順  枠番  馬番    斤量     単勝  course_len weather race_type  \\\n",
       "201901010101   1   1   1  54.0    1.4        18.0       曇         芝   \n",
       "201901010101   2   3   3  54.0    3.5        18.0       曇         芝   \n",
       "201901010101   3   4   4  51.0   46.6        18.0       曇         芝   \n",
       "201901010101   4   8   9  51.0   56.8        18.0       曇         芝   \n",
       "201901010101   5   5   5  54.0  140.3        18.0       曇         芝   \n",
       "...           ..  ..  ..   ...    ...         ...     ...       ...   \n",
       "201908040412   5   5   5  57.0   15.4        18.0       晴       ダート   \n",
       "201908040412   6   2   2  57.0   36.0        18.0       晴       ダート   \n",
       "201908040412   7   1   1  57.0    7.2        18.0       晴       ダート   \n",
       "201908040412   8   4   4  55.0   23.9        18.0       晴       ダート   \n",
       "201908040412   9   8   8  57.0    8.4        18.0       晴       ダート   \n",
       "\n",
       "             ground_state       date  ... first_to_rank_race_type_allR  \\\n",
       "201901010101            良 2019-07-27  ...                     5.000000   \n",
       "201901010101            良 2019-07-27  ...                     3.000000   \n",
       "201901010101            良 2019-07-27  ...                     0.000000   \n",
       "201901010101            良 2019-07-27  ...                     1.000000   \n",
       "201901010101            良 2019-07-27  ...                    -5.000000   \n",
       "...                   ...        ...  ...                          ...   \n",
       "201908040412            重 2019-10-13  ...                    -3.055556   \n",
       "201908040412            重 2019-10-13  ...                     1.536585   \n",
       "201908040412            重 2019-10-13  ...                     2.500000   \n",
       "201908040412            重 2019-10-13  ...                    -3.000000   \n",
       "201908040412            重 2019-10-13  ...                     0.125000   \n",
       "\n",
       "             first_to_final_race_type_allR  final_to_rank_race_type_allR  \\\n",
       "201901010101                      6.000000                     -1.000000   \n",
       "201901010101                      3.000000                      0.000000   \n",
       "201901010101                      0.000000                      0.000000   \n",
       "201901010101                     -2.000000                      3.000000   \n",
       "201901010101                     -2.000000                     -3.000000   \n",
       "...                                    ...                           ...   \n",
       "201908040412                      0.055556                     -3.111111   \n",
       "201908040412                      0.170732                      1.365854   \n",
       "201908040412                      1.722222                      0.777778   \n",
       "201908040412                     -0.333333                     -2.666667   \n",
       "201908040412                      0.750000                     -0.625000   \n",
       "\n",
       "             着順_開催_allR   賞金_開催_allR  着差_開催_allR  first_corner_開催_allR  \\\n",
       "201901010101   0.000000     0.000000    0.000000              0.000000   \n",
       "201901010101   0.000000     0.000000    0.000000              0.000000   \n",
       "201901010101   0.000000     0.000000    0.000000              0.000000   \n",
       "201901010101   0.000000     0.000000    0.000000              0.000000   \n",
       "201901010101   0.000000     0.000000    0.000000              0.000000   \n",
       "...                 ...          ...         ...                   ...   \n",
       "201908040412   1.000000  1535.700000    0.000000              3.000000   \n",
       "201908040412   6.750000   165.093750    1.081250              6.187500   \n",
       "201908040412   2.555556   438.311111    0.366667              5.111111   \n",
       "201908040412   4.666667   267.075000    0.625000              2.416667   \n",
       "201908040412   9.000000     0.000000    2.300000              2.000000   \n",
       "\n",
       "              first_to_rank_開催_allR  first_to_final_開催_allR  \\\n",
       "201901010101               0.000000                0.000000   \n",
       "201901010101               0.000000                0.000000   \n",
       "201901010101               0.000000                0.000000   \n",
       "201901010101               0.000000                0.000000   \n",
       "201901010101               0.000000                0.000000   \n",
       "...                             ...                     ...   \n",
       "201908040412               2.000000                0.000000   \n",
       "201908040412              -0.562500                0.250000   \n",
       "201908040412               2.555556                1.444444   \n",
       "201908040412              -2.250000                0.333333   \n",
       "201908040412              -7.000000                0.000000   \n",
       "\n",
       "              final_to_rank_開催_allR  \n",
       "201901010101               0.000000  \n",
       "201901010101               0.000000  \n",
       "201901010101               0.000000  \n",
       "201901010101               0.000000  \n",
       "201901010101               0.000000  \n",
       "...                             ...  \n",
       "201908040412               2.000000  \n",
       "201908040412              -0.812500  \n",
       "201908040412               1.111111  \n",
       "201908040412              -2.583333  \n",
       "201908040412              -7.000000  \n",
       "\n",
       "[47118 rows x 104 columns]"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#特徴量を増やす\n",
    "r.data_h.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec0149-9341-45bf-b979-7e717b9341ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'course_len', 'weather', 'race_type',\n",
    "       'ground_state', 'date', 'horse_id', \n",
    "    'jockey_id', 'rank', '性', '年齢',\n",
    "     '開催'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "40aac942-370a-444c-ae42-4c2f8ab5b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.data_pの特徴量をカテゴリ変数に変換する\n",
    "#引数にはregressorをTrueして制作した訓練データXを入力\n",
    "def categorical(X):\n",
    "    df = X.copy()\n",
    "    \n",
    "    weathers = df['weather'].unique()\n",
    "    race_types = df['race_type'].unique()\n",
    "    ground_states = df['ground_state'].unique()\n",
    "    sexes = df['性'].unique()\n",
    "    df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "    df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "    df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "    df['性'] = pd.Categorical(df['性'], sexes)\n",
    "    df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "52e0a880-6d40-4eeb-b7ea-f426d68adaaa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>体重変化</th>\n",
       "      <th>開催</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2017105318</td>\n",
       "      <td>05339</td>\n",
       "      <td>2</td>\n",
       "      <td>518</td>\n",
       "      <td>-16</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2017104612</td>\n",
       "      <td>05203</td>\n",
       "      <td>2</td>\n",
       "      <td>496</td>\n",
       "      <td>-8</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2017103879</td>\n",
       "      <td>01180</td>\n",
       "      <td>2</td>\n",
       "      <td>546</td>\n",
       "      <td>6</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2017106259</td>\n",
       "      <td>01179</td>\n",
       "      <td>2</td>\n",
       "      <td>458</td>\n",
       "      <td>-8</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2017104140</td>\n",
       "      <td>01062</td>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2018102912</td>\n",
       "      <td>01186</td>\n",
       "      <td>3</td>\n",
       "      <td>502</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2017100368</td>\n",
       "      <td>00732</td>\n",
       "      <td>4</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2018104097</td>\n",
       "      <td>01168</td>\n",
       "      <td>3</td>\n",
       "      <td>502</td>\n",
       "      <td>-10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2016105133</td>\n",
       "      <td>01115</td>\n",
       "      <td>5</td>\n",
       "      <td>436</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2015110065</td>\n",
       "      <td>01171</td>\n",
       "      <td>6</td>\n",
       "      <td>486</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130582 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              枠番  馬番    斤量    horse_id jockey_id  年齢   体重  体重変化  開催  n_horses  \\\n",
       "201901010101   1   1  54.0  2017105318     05339   2  518   -16  01         9   \n",
       "201901010101   3   3  54.0  2017104612     05203   2  496    -8  01         9   \n",
       "201901010101   4   4  51.0  2017103879     01180   2  546     6  01         9   \n",
       "201901010101   8   9  51.0  2017106259     01179   2  458    -8  01         9   \n",
       "201901010101   5   5  54.0  2017104140     01062   2  436     0  01         9   \n",
       "...           ..  ..   ...         ...       ...  ..  ...   ...  ..       ...   \n",
       "202110040812   2   2  51.0  2018102912     01186   3  502     8  10        11   \n",
       "202110040812   7   9  57.0  2017100368     00732   4  464     0  10        11   \n",
       "202110040812   7   8  53.0  2018104097     01168   3  502   -10  10        11   \n",
       "202110040812   8  10  57.0  2016105133     01115   5  436     2  10        11   \n",
       "202110040812   6   7  57.0  2015110065     01171   6  486    -2  10        11   \n",
       "\n",
       "              ...  race_type_芝  race_type_ダート  race_type_障害  ground_state_良  \\\n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "...           ...          ...            ...           ...             ...   \n",
       "202110040812  ...            1              0             0               1   \n",
       "202110040812  ...            1              0             0               1   \n",
       "202110040812  ...            1              0             0               1   \n",
       "202110040812  ...            1              0             0               1   \n",
       "202110040812  ...            1              0             0               1   \n",
       "\n",
       "              ground_state_不良  ground_state_稍重  ground_state_重  性_牡  性_牝  性_セ  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "...                       ...              ...             ...  ...  ...  ...  \n",
       "202110040812                0                0               0    1    0    0  \n",
       "202110040812                0                0               0    1    0    0  \n",
       "202110040812                0                0               0    1    0    0  \n",
       "202110040812                0                0               0    0    0    1  \n",
       "202110040812                0                0               0    0    0    1  \n",
       "\n",
       "[130582 rows x 26 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#特徴量をカテゴリ変数かした学習データ\n",
    "n_X = categorical(X)\n",
    "n_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e9a4c-b434-45a9-baef-55345bd83fb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " def process_categorical(self, le_horse, le_jockey, results_m):\n",
    "        df = self.data_pe.copy()\n",
    "        \n",
    "        #ラベルエンコーディング　horse_id,jockey_idを0始まりの整数に変換\n",
    "        mask_horse = df['horse_id'].isin(le_horse.classes_)\n",
    "        new_horse_id = df['horse_id'].mask(mask_horse).dropna().unique()\n",
    "        le_horse.classes_ = np.concatenate([le_horse.classes_, new_horse_id])\n",
    "        df['horse_id'] = le_horse.transform(df['horse_id'])\n",
    "        \n",
    "        mask_jockey = df['jockey_id'].isin(le_jockey.classes_)\n",
    "        new_jockey_id = df['jockey_id'].mask(mask_jockey).dropna().unique()\n",
    "        le_jockey.classes_ = np.concatenate([le_jockey.classes_, new_jockey_id])\n",
    "        df['jockey_id'] = le_jockey.transform(df['jockey_id'])\n",
    "        \n",
    "        df[\"horse_id\"] = df[\"horse_id\"].astype('category')\n",
    "        df[\"jockey_id\"] = df[\"jockey_id\"].astype('category')\n",
    "        \n",
    "        weathers = results_m['weather'].unique()\n",
    "        race_types = results_m['race_type'].unique()\n",
    "        ground_states = results_m['ground_state'].unique()\n",
    "        sexes = results_m['性'].unique()\n",
    "        df['weather'] = pd.Categorical(df['weather'], weathers)\n",
    "        df['race_type'] = pd.Categorical(df['race_type'], race_types)\n",
    "        df['ground_state'] = pd.Categorical(df['ground_state'], ground_states)\n",
    "        df['性'] = pd.Categorical(df['性'], sexes)\n",
    "        \n",
    "        df = pd.get_dummies(df, columns=['weather', 'race_type', 'ground_state', '性'])\n",
    "        #race_idを軸に馬番をsort\n",
    "        df = df.reset_index().sort_values([\"index\",\"馬番\"]).set_index('index')\n",
    "        df.index.name = None\n",
    "        \n",
    "        self.data_c = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "e0776049-c3e3-4e3c-964c-d163ac5b3849",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "n_X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "bb4ff0c6-d7b2-42a8-8e82-5b092a760b30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>体重変化</th>\n",
       "      <th>開催</th>\n",
       "      <th>n_horses</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202110040610</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2017100415</td>\n",
       "      <td>01174</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202008020512</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2014100750</td>\n",
       "      <td>01124</td>\n",
       "      <td>6</td>\n",
       "      <td>444</td>\n",
       "      <td>-6</td>\n",
       "      <td>08</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202107050710</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2017104055</td>\n",
       "      <td>01186</td>\n",
       "      <td>4</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>07</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202105040212</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2017105170</td>\n",
       "      <td>01127</td>\n",
       "      <td>4</td>\n",
       "      <td>536</td>\n",
       "      <td>0</td>\n",
       "      <td>05</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110010401</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2018109176</td>\n",
       "      <td>01168</td>\n",
       "      <td>3</td>\n",
       "      <td>446</td>\n",
       "      <td>-6</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201908040302</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2017106172</td>\n",
       "      <td>01126</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>-4</td>\n",
       "      <td>08</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201904010407</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2015103670</td>\n",
       "      <td>01177</td>\n",
       "      <td>4</td>\n",
       "      <td>490</td>\n",
       "      <td>8</td>\n",
       "      <td>04</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202106010104</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2017104947</td>\n",
       "      <td>01122</td>\n",
       "      <td>4</td>\n",
       "      <td>510</td>\n",
       "      <td>6</td>\n",
       "      <td>06</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202008040205</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2018106462</td>\n",
       "      <td>01182</td>\n",
       "      <td>2</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>08</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202009040511</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2015104571</td>\n",
       "      <td>01014</td>\n",
       "      <td>5</td>\n",
       "      <td>484</td>\n",
       "      <td>6</td>\n",
       "      <td>09</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26117 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              枠番  馬番    斤量    horse_id jockey_id  年齢   体重  体重変化  開催  n_horses  \\\n",
       "202110040610   7  14  52.0  2017100415     01174   4  450     4  10        16   \n",
       "202008020512   2   3  57.0  2014100750     01124   6  444    -6  08        15   \n",
       "202107050710   1   1  55.0  2017104055     01186   4  506     2  07        16   \n",
       "202105040212   5   9  57.0  2017105170     01127   4  536     0  05        16   \n",
       "202110010401   7   9  55.0  2018109176     01168   3  446    -6  10        11   \n",
       "...           ..  ..   ...         ...       ...  ..  ...   ...  ..       ...   \n",
       "201908040302   4   4  54.0  2017106172     01126   2  396    -4  08        11   \n",
       "201904010407   7   9  52.0  2015103670     01177   4  490     8  04        11   \n",
       "202106010104   5   8  56.0  2017104947     01122   4  510     6  06        15   \n",
       "202008040205   8  14  51.0  2018106462     01182   2  470     0  08        14   \n",
       "202009040511   6   7  56.0  2015104571     01014   5  484     6  09        12   \n",
       "\n",
       "              ...  race_type_芝  race_type_ダート  race_type_障害  ground_state_良  \\\n",
       "202110040610  ...            0              1             0               1   \n",
       "202008020512  ...            0              1             0               0   \n",
       "202107050710  ...            0              1             0               0   \n",
       "202105040212  ...            0              1             0               1   \n",
       "202110010401  ...            0              1             0               0   \n",
       "...           ...          ...            ...           ...             ...   \n",
       "201908040302  ...            1              0             0               0   \n",
       "201904010407  ...            0              1             0               1   \n",
       "202106010104  ...            0              1             0               1   \n",
       "202008040205  ...            1              0             0               0   \n",
       "202009040511  ...            0              1             0               1   \n",
       "\n",
       "              ground_state_不良  ground_state_稍重  ground_state_重  性_牡  性_牝  性_セ  \n",
       "202110040610                0                0               0    0    1    0  \n",
       "202008020512                0                1               0    1    0    0  \n",
       "202107050710                1                0               0    1    0    0  \n",
       "202105040212                0                0               0    1    0    0  \n",
       "202110010401                1                0               0    0    0    1  \n",
       "...                       ...              ...             ...  ...  ...  ...  \n",
       "201908040302                1                0               0    0    1    0  \n",
       "201904010407                0                0               0    0    1    0  \n",
       "202106010104                0                0               0    1    0    0  \n",
       "202008040205                0                1               0    0    1    0  \n",
       "202009040511                0                0               0    1    0    0  \n",
       "\n",
       "[26117 rows x 26 columns]"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "1fea05b6-0275-47a4-aef4-8aa9f6351bae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2.247616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2.252953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2.254059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2.256253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2.256526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>2.306105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>2.306317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>2.306317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>2.306530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202110040812</th>\n",
       "      <td>2.306742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130582 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rls\n",
       "201901010101  2.247616\n",
       "201901010101  2.252953\n",
       "201901010101  2.254059\n",
       "201901010101  2.256253\n",
       "201901010101  2.256526\n",
       "...                ...\n",
       "202110040812  2.306105\n",
       "202110040812  2.306317\n",
       "202110040812  2.306317\n",
       "202110040812  2.306530\n",
       "202110040812  2.306742\n",
       "\n",
       "[130582 rows x 1 columns]"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#正答データ\n",
    "r.data_p[[\"rls\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "b738716a-70f4-485a-bd53-9b33c50a7052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_r = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "3df3ce06-ee60-4ea6-b2e7-1008752d38a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4420966013949088"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#r^2score\n",
    "rf_r.predict(X_test)\n",
    "rf_r.score(X_test,y_test)\n",
    "score_ = rf_r.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "4976a4e1-11d4-483c-85a6-7a22f6d83d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjusted2関数\n",
    "#左からr2スコア、検証結果、特徴量数を入力\n",
    "def adj_r2_score(r2_score,y_test,p=X_test.shape[1] -1):\n",
    "    return 1-(1-score_)*\\\n",
    "    ((len(y_test)-1)/(len(y_test) - p -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "df73db3f-b6c2-450d-b91e-c91e79261ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4415620268303031"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_r2_score(score_,y_test,X_test.shape[1] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "878e69b2-d8a9-4cf8-a3e6-e0fe97512371",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "\t枠番         : 0.024367\n",
      "\t馬番         : 0.045676\n",
      "\t斤量         : 0.032853\n",
      "\thorse_id   : 0.137933\n",
      "\tjockey_id  : 0.092183\n",
      "\t年齢         : 0.040562\n",
      "\t体重         : 0.099305\n",
      "\t体重変化       : 0.065208\n",
      "\t開催         : 0.118571\n",
      "\tn_horses   : 0.087101\n",
      "\tweather_曇  : 0.013799\n",
      "\tweather_晴  : 0.013467\n",
      "\tweather_雨  : 0.007499\n",
      "\tweather_小雨 : 0.008982\n",
      "\tweather_小雪 : 0.000072\n",
      "\tweather_雪  : 0.000282\n",
      "\trace_type_芝 : 0.016256\n",
      "\trace_type_ダート : 0.016013\n",
      "\trace_type_障害 : 0.117385\n",
      "\tground_state_良 : 0.012563\n",
      "\tground_state_不良 : 0.006891\n",
      "\tground_state_稍重 : 0.012082\n",
      "\tground_state_重 : 0.009171\n",
      "\t性_牡        : 0.002695\n",
      "\t性_牝        : 0.016788\n",
      "\t性_セ        : 0.002295\n"
     ]
    }
   ],
   "source": [
    "rf_i = rf_r.feature_importances_\n",
    "\n",
    "print('Feature Importances:')\n",
    "\n",
    "for i, feat in enumerate(n_X.columns):\n",
    "    print('\\t{0:10s} : {1:>.6f}'.format(feat, rf_i[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66cc2a7-8b32-4344-9ccf-32c83a873d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "be67d582-ba55-47e1-8224-da7726c898f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "e5178b5e-834e-4be9-9c39-72cb9dc496d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(estimator=model,\n",
    "                         param_grid=parameters,\n",
    "                         scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "89d38ca6-1fdc-4ef8-a578-19133285b5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             n_jobs=None,\n",
       "             param_grid={'max_depth': (10, 20, 30, 40, 50, None),\n",
       "                         'max_features': ('sqrt', 'log2', 'auto', None),\n",
       "                         'n_estimators': [10, 20, 30, 50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fcbd9-5249-4dc7-b6c8-fa2f45ec9f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "f733df65-6db9-4311-8686-5d8eb00e4d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4475777806356849"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = rf_r.predict(X_test)\n",
    "rf_r.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "bd18521c-ac6a-4541-8da1-54a8c34808ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe40a1bbc70>"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(y_test,label=\"True\")\n",
    "plt.plot(predicted, label=\"predicted\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "0c559cbd-0c9e-4d3a-88da-b19dab2c8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parames 最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "90770d39-a450-43ba-833c-19896aac68b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    criterion = trial.suggest_categorical('criterion', ['mae'])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap',['True'])\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 100)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto'])\n",
    "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 1,100)\n",
    "    n_estimators =  trial.suggest_int('n_estimators', 1, 100)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split',2,5)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf',1,10)\n",
    "    \n",
    "    regr = RandomForestRegressor(bootstrap = bootstrap, criterion = criterion,\n",
    "                                 max_depth = max_depth, max_features = max_features,\n",
    "                                 max_leaf_nodes = max_leaf_nodes,n_estimators = n_estimators,\n",
    "                                 min_samples_split = min_samples_split,min_samples_leaf = min_samples_leaf,\n",
    "                                 n_jobs=2)\n",
    "    \n",
    "    score = cross_val_score(regr, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "    r2_mean = score.mean()\n",
    "    print(r2_mean)\n",
    "\n",
    "    return r2_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "56dc5387-f0c7-45f2-a708-b6cf3643f8a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-01-15 06:31:12,814]\u001b[0m A new study created in memory with name: no-name-0083c376-02d7-4b18-9b0b-a8aa616507eb\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/fn98hw1541vg9yshhxdqfgc80000gn/T/ipykernel_42740/2245720619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/tm/fn98hw1541vg9yshhxdqfgc80000gn/T/ipykernel_42740/2059744658.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     15\u001b[0m                                  n_jobs=2)\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mr2_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 250\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5bdb1af7-dfa1-4b1a-98a5-7e4ff711d40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = pd.DataFrame(r.data_h.index.unique())\n",
    "samples = sample.sample(100)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3c2f179e-a4f0-45e3-bc2f-5010d1161fc2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_s = r.data_h.loc[samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bccb38e8-d073-4abd-9b42-b83479cec4cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_530d2_row3_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_530d2_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_530d2_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_530d2_row0_col1\" class=\"data row0 col1\" >1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_530d2_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_530d2_row1_col1\" class=\"data row1 col1\" >rls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_530d2_row2_col0\" class=\"data row2 col0\" >Original Data</td>\n",
       "      <td id=\"T_530d2_row2_col1\" class=\"data row2 col1\" >(1359, 104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_530d2_row3_col0\" class=\"data row3 col0\" >Missing Values</td>\n",
       "      <td id=\"T_530d2_row3_col1\" class=\"data row3 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_530d2_row4_col0\" class=\"data row4 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_530d2_row4_col1\" class=\"data row4 col1\" >91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_530d2_row5_col0\" class=\"data row5 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_530d2_row5_col1\" class=\"data row5 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_530d2_row6_col0\" class=\"data row6 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_530d2_row6_col1\" class=\"data row6 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_530d2_row7_col0\" class=\"data row7 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_530d2_row7_col1\" class=\"data row7 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_530d2_row8_col0\" class=\"data row8 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_530d2_row8_col1\" class=\"data row8 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_530d2_row9_col0\" class=\"data row9 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_530d2_row9_col1\" class=\"data row9 col1\" >(951, 558)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_530d2_row10_col0\" class=\"data row10 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_530d2_row10_col1\" class=\"data row10 col1\" >(408, 558)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_530d2_row11_col0\" class=\"data row11 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_530d2_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_530d2_row12_col0\" class=\"data row12 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_530d2_row12_col1\" class=\"data row12 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_530d2_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_530d2_row13_col1\" class=\"data row13 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_530d2_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_530d2_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_530d2_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_530d2_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_530d2_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_530d2_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_530d2_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_530d2_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_530d2_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_530d2_row18_col1\" class=\"data row18 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_530d2_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_530d2_row19_col1\" class=\"data row19 col1\" >f8c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_530d2_row20_col0\" class=\"data row20 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_530d2_row20_col1\" class=\"data row20 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_530d2_row21_col0\" class=\"data row21 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_530d2_row21_col1\" class=\"data row21 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_530d2_row22_col0\" class=\"data row22 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_530d2_row22_col1\" class=\"data row22 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_530d2_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_530d2_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_530d2_row24_col0\" class=\"data row24 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_530d2_row24_col1\" class=\"data row24 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_530d2_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_530d2_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_530d2_row26_col0\" class=\"data row26 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_530d2_row26_col1\" class=\"data row26 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_530d2_row27_col0\" class=\"data row27 col0\" >Normalize</td>\n",
       "      <td id=\"T_530d2_row27_col1\" class=\"data row27 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_530d2_row28_col0\" class=\"data row28 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_530d2_row28_col1\" class=\"data row28 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_530d2_row29_col0\" class=\"data row29 col0\" >Transformation</td>\n",
       "      <td id=\"T_530d2_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_530d2_row30_col0\" class=\"data row30 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_530d2_row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_530d2_row31_col0\" class=\"data row31 col0\" >PCA</td>\n",
       "      <td id=\"T_530d2_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_530d2_row32_col0\" class=\"data row32 col0\" >PCA Method</td>\n",
       "      <td id=\"T_530d2_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_530d2_row33_col0\" class=\"data row33 col0\" >PCA Components</td>\n",
       "      <td id=\"T_530d2_row33_col1\" class=\"data row33 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_530d2_row34_col0\" class=\"data row34 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_530d2_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_530d2_row35_col0\" class=\"data row35 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_530d2_row35_col1\" class=\"data row35 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_530d2_row36_col0\" class=\"data row36 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_530d2_row36_col1\" class=\"data row36 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_530d2_row37_col0\" class=\"data row37 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_530d2_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_530d2_row38_col0\" class=\"data row38 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_530d2_row38_col1\" class=\"data row38 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_530d2_row39_col0\" class=\"data row39 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_530d2_row39_col1\" class=\"data row39 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_530d2_row40_col0\" class=\"data row40 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_530d2_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_530d2_row41_col0\" class=\"data row41 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_530d2_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_530d2_row42_col0\" class=\"data row42 col0\" >Clustering</td>\n",
       "      <td id=\"T_530d2_row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_530d2_row43_col0\" class=\"data row43 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_530d2_row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_530d2_row44_col0\" class=\"data row44 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_530d2_row44_col1\" class=\"data row44 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_530d2_row45_col0\" class=\"data row45 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_530d2_row45_col1\" class=\"data row45 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_530d2_row46_col0\" class=\"data row46 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_530d2_row46_col1\" class=\"data row46 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_530d2_row47_col0\" class=\"data row47 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_530d2_row47_col1\" class=\"data row47 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_530d2_row48_col0\" class=\"data row48 col0\" >Group Features</td>\n",
       "      <td id=\"T_530d2_row48_col1\" class=\"data row48 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_530d2_row49_col0\" class=\"data row49 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_530d2_row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_530d2_row50_col0\" class=\"data row50 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_530d2_row50_col1\" class=\"data row50 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_530d2_row51_col0\" class=\"data row51 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_530d2_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_530d2_row52_col0\" class=\"data row52 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_530d2_row52_col1\" class=\"data row52 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_530d2_row53_col0\" class=\"data row53 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_530d2_row53_col1\" class=\"data row53 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_530d2_row54_col0\" class=\"data row54 col0\" >Transform Target</td>\n",
       "      <td id=\"T_530d2_row54_col1\" class=\"data row54 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_530d2_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_530d2_row55_col0\" class=\"data row55 col0\" >Transform Target Method</td>\n",
       "      <td id=\"T_530d2_row55_col1\" class=\"data row55 col1\" >box-cox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe536ca4910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Simple_Imputer' object has no attribute 'fill_value_categorical'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tm/fn98hw1541vg9yshhxdqfgc80000gn/T/ipykernel_42740/3093168664.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m regression_model = setup(data_s, target='rls', fold_shuffle=True,\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mignore_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"着順\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rank\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"単勝\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"second\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mcategorical_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"jockey_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"horse_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             numeric_features=[\"枠番\",\"馬番\",\"斤量\",\"n_horses\"])\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/regression.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(data, target, train_size, test_data, preprocess, imputation_type, iterative_imputation_iters, categorical_features, categorical_imputation, categorical_iterative_imputer, ordinal_features, high_cardinality_features, high_cardinality_method, numeric_features, numeric_imputation, numeric_iterative_imputer, date_features, ignore_features, normalize, normalize_method, transformation, transformation_method, handle_unknown_categorical, unknown_categorical_method, pca, pca_method, pca_components, ignore_low_variance, combine_rare_levels, rare_level_threshold, bin_numeric_features, remove_outliers, outliers_threshold, remove_multicollinearity, multicollinearity_threshold, remove_perfect_collinearity, create_clusters, cluster_iter, polynomial_features, polynomial_degree, trigonometry_features, polynomial_threshold, group_features, group_names, feature_selection, feature_selection_threshold, feature_selection_method, feature_interaction, feature_ratio, interaction_threshold, transform_target, transform_target_method, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, custom_pipeline, html, session_id, log_experiment, experiment_name, log_plots, log_profile, log_data, silent, verbose, profile, profile_kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mlog_plots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"residuals\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     return pycaret.internal.tabular.setup(\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mml_usecase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mavailable_plots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mavailable_plots\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pycaret/internal/tabular.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(data, target, ml_usecase, available_plots, train_size, test_data, preprocess, imputation_type, iterative_imputation_iters, categorical_features, categorical_imputation, categorical_iterative_imputer, ordinal_features, high_cardinality_features, high_cardinality_method, numeric_features, numeric_imputation, numeric_iterative_imputer, date_features, ignore_features, normalize, normalize_method, transformation, transformation_method, handle_unknown_categorical, unknown_categorical_method, pca, pca_method, pca_components, ignore_low_variance, combine_rare_levels, rare_level_threshold, bin_numeric_features, remove_outliers, outliers_threshold, remove_multicollinearity, multicollinearity_threshold, remove_perfect_collinearity, create_clusters, cluster_iter, polynomial_features, polynomial_degree, trigonometry_features, polynomial_threshold, group_features, group_names, feature_selection, feature_selection_threshold, feature_selection_method, feature_interaction, feature_ratio, interaction_threshold, fix_imbalance, fix_imbalance_method, transform_target, transform_target_method, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, custom_pipeline, html, session_id, log_experiment, experiment_name, log_plots, log_profile, log_data, silent, verbose, profile, profile_kwargs, display)\u001b[0m\n\u001b[1;32m   1748\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"display_container: {len(display_container)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_pipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"setup() succesfully completed......................................\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    258\u001b[0m             n_max_elements_to_show=N_MAX_ELEMENTS_TO_SHOW)\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mrepr_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0msio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0m\u001b[1;32m    405\u001b[0m                                                 self._depth, level)\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         return _safe_repr(object, context, maxlevels, level,\n\u001b[0m\u001b[1;32m    181\u001b[0m                           changed_only=self._changed_only)\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    434\u001b[0m             krepr, kreadable, krecur = saferepr(\n\u001b[1;32m    435\u001b[0m                 k, context, maxlevels, level, changed_only=changed_only)\n\u001b[0;32m--> 436\u001b[0;31m             vrepr, vreadable, vrecur = saferepr(\n\u001b[0m\u001b[1;32m    437\u001b[0m                 v, context, maxlevels, level, changed_only=changed_only)\n\u001b[1;32m    438\u001b[0m             \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s=%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkrepr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             orepr, oreadable, orecur = _safe_repr(\n\u001b[0m\u001b[1;32m    406\u001b[0m                 o, context, maxlevels, level, changed_only=changed_only)\n\u001b[1;32m    407\u001b[0m             \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             orepr, oreadable, orecur = _safe_repr(\n\u001b[0m\u001b[1;32m    406\u001b[0m                 o, context, maxlevels, level, changed_only=changed_only)\n\u001b[1;32m    407\u001b[0m             \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/_pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_changed_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mappend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mdeep_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Simple_Imputer' object has no attribute 'fill_value_categorical'"
     ]
    }
   ],
   "source": [
    "regression_model = setup(data_s, target='rls', fold_shuffle=True,\n",
    "            ignore_features=[\"着順\",\"rank\",\"単勝\",\"second\"], \n",
    "            categorical_features=[\"jockey_id\",\"horse_id\"],\n",
    "            numeric_features=[\"枠番\",\"馬番\",\"斤量\",\"n_horses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "136942bc-73aa-4c2c-a1f0-f1749213c13b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1da91_row10_col0, #T_1da91_row10_col1, #T_1da91_row10_col2, #T_1da91_row10_col3, #T_1da91_row10_col4, #T_1da91_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1da91_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1da91_row0_col0\" class=\"data row0 col0\" >0.0186</td>\n",
       "      <td id=\"T_1da91_row0_col1\" class=\"data row0 col1\" >0.0005</td>\n",
       "      <td id=\"T_1da91_row0_col2\" class=\"data row0 col2\" >0.0220</td>\n",
       "      <td id=\"T_1da91_row0_col3\" class=\"data row0 col3\" >0.8597</td>\n",
       "      <td id=\"T_1da91_row0_col4\" class=\"data row0 col4\" >0.0068</td>\n",
       "      <td id=\"T_1da91_row0_col5\" class=\"data row0 col5\" >0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1da91_row1_col0\" class=\"data row1 col0\" >0.0223</td>\n",
       "      <td id=\"T_1da91_row1_col1\" class=\"data row1 col1\" >0.0006</td>\n",
       "      <td id=\"T_1da91_row1_col2\" class=\"data row1 col2\" >0.0252</td>\n",
       "      <td id=\"T_1da91_row1_col3\" class=\"data row1 col3\" >0.8187</td>\n",
       "      <td id=\"T_1da91_row1_col4\" class=\"data row1 col4\" >0.0078</td>\n",
       "      <td id=\"T_1da91_row1_col5\" class=\"data row1 col5\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1da91_row2_col0\" class=\"data row2 col0\" >0.0185</td>\n",
       "      <td id=\"T_1da91_row2_col1\" class=\"data row2 col1\" >0.0006</td>\n",
       "      <td id=\"T_1da91_row2_col2\" class=\"data row2 col2\" >0.0247</td>\n",
       "      <td id=\"T_1da91_row2_col3\" class=\"data row2 col3\" >0.8720</td>\n",
       "      <td id=\"T_1da91_row2_col4\" class=\"data row2 col4\" >0.0077</td>\n",
       "      <td id=\"T_1da91_row2_col5\" class=\"data row2 col5\" >0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1da91_row3_col0\" class=\"data row3 col0\" >0.0183</td>\n",
       "      <td id=\"T_1da91_row3_col1\" class=\"data row3 col1\" >0.0005</td>\n",
       "      <td id=\"T_1da91_row3_col2\" class=\"data row3 col2\" >0.0220</td>\n",
       "      <td id=\"T_1da91_row3_col3\" class=\"data row3 col3\" >0.8833</td>\n",
       "      <td id=\"T_1da91_row3_col4\" class=\"data row3 col4\" >0.0068</td>\n",
       "      <td id=\"T_1da91_row3_col5\" class=\"data row3 col5\" >0.0082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1da91_row4_col0\" class=\"data row4 col0\" >0.0186</td>\n",
       "      <td id=\"T_1da91_row4_col1\" class=\"data row4 col1\" >0.0005</td>\n",
       "      <td id=\"T_1da91_row4_col2\" class=\"data row4 col2\" >0.0215</td>\n",
       "      <td id=\"T_1da91_row4_col3\" class=\"data row4 col3\" >0.8884</td>\n",
       "      <td id=\"T_1da91_row4_col4\" class=\"data row4 col4\" >0.0066</td>\n",
       "      <td id=\"T_1da91_row4_col5\" class=\"data row4 col5\" >0.0084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1da91_row5_col0\" class=\"data row5 col0\" >0.0206</td>\n",
       "      <td id=\"T_1da91_row5_col1\" class=\"data row5 col1\" >0.0006</td>\n",
       "      <td id=\"T_1da91_row5_col2\" class=\"data row5 col2\" >0.0243</td>\n",
       "      <td id=\"T_1da91_row5_col3\" class=\"data row5 col3\" >0.8357</td>\n",
       "      <td id=\"T_1da91_row5_col4\" class=\"data row5 col4\" >0.0075</td>\n",
       "      <td id=\"T_1da91_row5_col5\" class=\"data row5 col5\" >0.0092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1da91_row6_col0\" class=\"data row6 col0\" >0.0183</td>\n",
       "      <td id=\"T_1da91_row6_col1\" class=\"data row6 col1\" >0.0004</td>\n",
       "      <td id=\"T_1da91_row6_col2\" class=\"data row6 col2\" >0.0209</td>\n",
       "      <td id=\"T_1da91_row6_col3\" class=\"data row6 col3\" >0.8870</td>\n",
       "      <td id=\"T_1da91_row6_col4\" class=\"data row6 col4\" >0.0065</td>\n",
       "      <td id=\"T_1da91_row6_col5\" class=\"data row6 col5\" >0.0083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1da91_row7_col0\" class=\"data row7 col0\" >0.0209</td>\n",
       "      <td id=\"T_1da91_row7_col1\" class=\"data row7 col1\" >0.0008</td>\n",
       "      <td id=\"T_1da91_row7_col2\" class=\"data row7 col2\" >0.0276</td>\n",
       "      <td id=\"T_1da91_row7_col3\" class=\"data row7 col3\" >0.7980</td>\n",
       "      <td id=\"T_1da91_row7_col4\" class=\"data row7 col4\" >0.0086</td>\n",
       "      <td id=\"T_1da91_row7_col5\" class=\"data row7 col5\" >0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1da91_row8_col0\" class=\"data row8 col0\" >0.0214</td>\n",
       "      <td id=\"T_1da91_row8_col1\" class=\"data row8 col1\" >0.0006</td>\n",
       "      <td id=\"T_1da91_row8_col2\" class=\"data row8 col2\" >0.0244</td>\n",
       "      <td id=\"T_1da91_row8_col3\" class=\"data row8 col3\" >0.8430</td>\n",
       "      <td id=\"T_1da91_row8_col4\" class=\"data row8 col4\" >0.0075</td>\n",
       "      <td id=\"T_1da91_row8_col5\" class=\"data row8 col5\" >0.0096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1da91_row9_col0\" class=\"data row9 col0\" >0.0178</td>\n",
       "      <td id=\"T_1da91_row9_col1\" class=\"data row9 col1\" >0.0005</td>\n",
       "      <td id=\"T_1da91_row9_col2\" class=\"data row9 col2\" >0.0212</td>\n",
       "      <td id=\"T_1da91_row9_col3\" class=\"data row9 col3\" >0.8981</td>\n",
       "      <td id=\"T_1da91_row9_col4\" class=\"data row9 col4\" >0.0066</td>\n",
       "      <td id=\"T_1da91_row9_col5\" class=\"data row9 col5\" >0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_1da91_row10_col0\" class=\"data row10 col0\" >0.0195</td>\n",
       "      <td id=\"T_1da91_row10_col1\" class=\"data row10 col1\" >0.0006</td>\n",
       "      <td id=\"T_1da91_row10_col2\" class=\"data row10 col2\" >0.0234</td>\n",
       "      <td id=\"T_1da91_row10_col3\" class=\"data row10 col3\" >0.8584</td>\n",
       "      <td id=\"T_1da91_row10_col4\" class=\"data row10 col4\" >0.0072</td>\n",
       "      <td id=\"T_1da91_row10_col5\" class=\"data row10 col5\" >0.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1da91_level0_row11\" class=\"row_heading level0 row11\" >SD</th>\n",
       "      <td id=\"T_1da91_row11_col0\" class=\"data row11 col0\" >0.0015</td>\n",
       "      <td id=\"T_1da91_row11_col1\" class=\"data row11 col1\" >0.0001</td>\n",
       "      <td id=\"T_1da91_row11_col2\" class=\"data row11 col2\" >0.0021</td>\n",
       "      <td id=\"T_1da91_row11_col3\" class=\"data row11 col3\" >0.0317</td>\n",
       "      <td id=\"T_1da91_row11_col4\" class=\"data row11 col4\" >0.0007</td>\n",
       "      <td id=\"T_1da91_row11_col5\" class=\"data row11 col5\" >0.0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe537ded400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune = tune_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100baccb-893d-4f08-ad61-63d003a7a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random forest regressorで回帰を行う　目的変数はroot log second\n",
    "学習モデルを学習させる　パラメータを取得\n",
    "テストデータで確認　race_idごとにレースタイム予測値を出力　\n",
    "レースタイムの少ない順に1,2,3をわりふり、賭ける\n",
    "\n",
    "直近　rbgtの実装を行い、各レースのレースタイムを出力、プロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "944f22ac-a220-4663-9f58-06a1d58d0323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "01021a54-c84a-4765-9f16-5e7c2378e739",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>年齢</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10614</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>114.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8270</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10194</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9851</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9967</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6372</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3782</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3136</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3495</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3331</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47118 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              着順  枠番  馬番    斤量     単勝  course_len horse_id jockey_id  rank  \\\n",
       "201901010101   1   1   1  54.0    1.4        18.0    10614       152     1   \n",
       "201901010101   7   2   2  54.0  114.7        18.0     8270        73     0   \n",
       "201901010101   2   3   3  54.0    3.5        18.0    10194       142     1   \n",
       "201901010101   3   4   4  51.0   46.6        18.0     9851       136     1   \n",
       "201901010101   5   5   5  54.0  140.3        18.0     9967        47     0   \n",
       "...           ..  ..  ..   ...    ...         ...      ...       ...   ...   \n",
       "201910021212  15   6  12  52.0   17.5        26.0     6372         5     0   \n",
       "201910021212   5   7  13  57.0    7.7        26.0     3782        28     0   \n",
       "201910021212   1   7  14  57.0    4.4        26.0     3136        77     1   \n",
       "201910021212   3   8  15  57.0   21.9        26.0     3495        87     1   \n",
       "201910021212  11   8  16  55.0   15.1        26.0     3331        27     0   \n",
       "\n",
       "              年齢  ...  race_type_芝  race_type_ダート  race_type_障害  \\\n",
       "201901010101   2  ...            1              0             0   \n",
       "201901010101   2  ...            1              0             0   \n",
       "201901010101   2  ...            1              0             0   \n",
       "201901010101   2  ...            1              0             0   \n",
       "201901010101   2  ...            1              0             0   \n",
       "...           ..  ...          ...            ...           ...   \n",
       "201910021212   3  ...            1              0             0   \n",
       "201910021212   4  ...            1              0             0   \n",
       "201910021212   4  ...            1              0             0   \n",
       "201910021212   4  ...            1              0             0   \n",
       "201910021212   4  ...            1              0             0   \n",
       "\n",
       "              ground_state_良  ground_state_不良 ground_state_稍重 ground_state_重  \\\n",
       "201901010101               1                0               0              0   \n",
       "201901010101               1                0               0              0   \n",
       "201901010101               1                0               0              0   \n",
       "201901010101               1                0               0              0   \n",
       "201901010101               1                0               0              0   \n",
       "...                      ...              ...             ...            ...   \n",
       "201910021212               0                0               0              1   \n",
       "201910021212               0                0               0              1   \n",
       "201910021212               0                0               0              1   \n",
       "201910021212               0                0               0              1   \n",
       "201910021212               0                0               0              1   \n",
       "\n",
       "             性_牡 性_牝 性_セ  \n",
       "201901010101   1   0   0  \n",
       "201901010101   0   1   0  \n",
       "201901010101   1   0   0  \n",
       "201901010101   1   0   0  \n",
       "201901010101   1   0   0  \n",
       "...           ..  ..  ..  \n",
       "201910021212   0   1   0  \n",
       "201910021212   1   0   0  \n",
       "201910021212   1   0   0  \n",
       "201910021212   1   0   0  \n",
       "201910021212   0   1   0  \n",
       "\n",
       "[47118 rows x 93 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5fd117be-875c-4fc3-a7f5-765a95a756b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ind = np.argsort(rf.feature_importances_)[::-1]\n",
    "imp = rf.feature_importances_[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b77f63ef-339e-4851-97c0-5afa57aec3d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        92\n",
       "4803     11\n",
       "27391     7\n",
       "7713      7\n",
       "16179     7\n",
       "24007     7\n",
       "18378     7\n",
       "8520      5\n",
       "19101     5\n",
       "8227      5\n",
       "21296     5\n",
       "4805      5\n",
       "4804      5\n",
       "8517      2\n",
       "19097     2\n",
       "8226      2\n",
       "21289     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ef2a1-860a-4fac-8fcd-281582804a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "529a4af3-1c2c-40c8-9aa7-47499a8cc9cf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['着順',\n",
       " '枠番',\n",
       " '馬番',\n",
       " '斤量',\n",
       " '単勝',\n",
       " 'course_len',\n",
       " 'horse_id',\n",
       " 'jockey_id',\n",
       " '年齢',\n",
       " '体重',\n",
       " '体重変化',\n",
       " 'second',\n",
       " 'rls',\n",
       " 'n_horses',\n",
       " '着順_5R',\n",
       " '賞金_5R',\n",
       " '着差_5R',\n",
       " 'first_corner_5R',\n",
       " 'first_to_rank_5R',\n",
       " 'first_to_final_5R',\n",
       " 'final_to_rank_5R',\n",
       " '着順_course_len_5R',\n",
       " '賞金_course_len_5R',\n",
       " '着差_course_len_5R',\n",
       " 'first_corner_course_len_5R',\n",
       " 'first_to_rank_course_len_5R',\n",
       " 'first_to_final_course_len_5R',\n",
       " 'final_to_rank_course_len_5R',\n",
       " '着順_race_type_5R',\n",
       " '賞金_race_type_5R',\n",
       " '着差_race_type_5R',\n",
       " 'first_corner_race_type_5R',\n",
       " 'first_to_rank_race_type_5R',\n",
       " 'first_to_final_race_type_5R',\n",
       " 'final_to_rank_race_type_5R',\n",
       " '着順_開催_5R',\n",
       " '賞金_開催_5R',\n",
       " '着差_開催_5R',\n",
       " 'first_corner_開催_5R',\n",
       " 'first_to_rank_開催_5R',\n",
       " 'first_to_final_開催_5R',\n",
       " 'final_to_rank_開催_5R',\n",
       " '着順_9R',\n",
       " '賞金_9R',\n",
       " '着差_9R',\n",
       " 'first_corner_9R',\n",
       " 'first_to_rank_9R',\n",
       " 'first_to_final_9R',\n",
       " 'final_to_rank_9R',\n",
       " '着順_course_len_9R',\n",
       " '賞金_course_len_9R',\n",
       " '着差_course_len_9R',\n",
       " 'first_corner_course_len_9R',\n",
       " 'first_to_rank_course_len_9R',\n",
       " 'first_to_final_course_len_9R',\n",
       " 'final_to_rank_course_len_9R',\n",
       " '着順_race_type_9R',\n",
       " '賞金_race_type_9R',\n",
       " '着差_race_type_9R',\n",
       " 'first_corner_race_type_9R',\n",
       " 'first_to_rank_race_type_9R',\n",
       " 'first_to_final_race_type_9R',\n",
       " 'final_to_rank_race_type_9R',\n",
       " '着順_開催_9R',\n",
       " '賞金_開催_9R',\n",
       " '着差_開催_9R',\n",
       " 'first_corner_開催_9R',\n",
       " 'first_to_rank_開催_9R',\n",
       " 'first_to_final_開催_9R',\n",
       " 'final_to_rank_開催_9R',\n",
       " '着順_allR',\n",
       " '賞金_allR',\n",
       " '着差_allR',\n",
       " 'first_corner_allR',\n",
       " 'first_to_rank_allR',\n",
       " 'first_to_final_allR',\n",
       " 'final_to_rank_allR',\n",
       " '着順_course_len_allR',\n",
       " '賞金_course_len_allR',\n",
       " '着差_course_len_allR',\n",
       " 'first_corner_course_len_allR',\n",
       " 'first_to_rank_course_len_allR',\n",
       " 'first_to_final_course_len_allR',\n",
       " 'final_to_rank_course_len_allR',\n",
       " '着順_race_type_allR',\n",
       " '賞金_race_type_allR',\n",
       " '着差_race_type_allR',\n",
       " 'first_corner_race_type_allR',\n",
       " 'first_to_rank_race_type_allR',\n",
       " 'first_to_final_race_type_allR',\n",
       " 'final_to_rank_race_type_allR',\n",
       " '着順_開催_allR',\n",
       " '賞金_開催_allR',\n",
       " '着差_開催_allR',\n",
       " 'first_corner_開催_allR',\n",
       " 'first_to_rank_開催_allR',\n",
       " 'first_to_final_開催_allR',\n",
       " 'final_to_rank_開催_allR',\n",
       " 'peds_0',\n",
       " 'peds_1',\n",
       " 'peds_2',\n",
       " 'peds_3',\n",
       " 'peds_4',\n",
       " 'peds_5',\n",
       " 'peds_6',\n",
       " 'peds_7',\n",
       " 'peds_8',\n",
       " 'peds_9',\n",
       " 'peds_10',\n",
       " 'peds_11',\n",
       " 'peds_12',\n",
       " 'peds_13',\n",
       " 'peds_14',\n",
       " 'peds_15',\n",
       " 'peds_16',\n",
       " 'peds_17',\n",
       " 'peds_18',\n",
       " 'peds_19',\n",
       " 'peds_20',\n",
       " 'peds_21',\n",
       " 'peds_22',\n",
       " 'peds_23',\n",
       " 'peds_24',\n",
       " 'peds_25',\n",
       " 'peds_26',\n",
       " 'peds_27',\n",
       " 'peds_28',\n",
       " 'peds_29',\n",
       " 'peds_30',\n",
       " 'peds_31',\n",
       " 'peds_32',\n",
       " 'peds_33',\n",
       " 'peds_34',\n",
       " 'peds_35',\n",
       " 'peds_36',\n",
       " 'peds_37',\n",
       " 'peds_38',\n",
       " 'peds_39',\n",
       " 'peds_40',\n",
       " 'peds_41',\n",
       " 'peds_42',\n",
       " 'peds_43',\n",
       " 'peds_44',\n",
       " 'peds_45',\n",
       " 'peds_46',\n",
       " 'peds_47',\n",
       " 'peds_48',\n",
       " 'peds_49',\n",
       " 'peds_50',\n",
       " 'peds_51',\n",
       " 'peds_52',\n",
       " 'peds_53',\n",
       " 'peds_54',\n",
       " 'peds_55',\n",
       " 'peds_56',\n",
       " 'peds_57',\n",
       " 'peds_58',\n",
       " 'peds_59',\n",
       " 'peds_60',\n",
       " 'peds_61',\n",
       " 'weather_曇',\n",
       " 'weather_晴',\n",
       " 'weather_小雨',\n",
       " 'weather_雨',\n",
       " 'weather_小雪',\n",
       " 'weather_雪',\n",
       " 'race_type_芝',\n",
       " 'race_type_ダート',\n",
       " 'race_type_障害',\n",
       " 'ground_state_良',\n",
       " 'ground_state_不良',\n",
       " 'ground_state_稍重',\n",
       " 'ground_state_重',\n",
       " '性_牡',\n",
       " '性_牝',\n",
       " '性_セ']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X.columns[i] for i in range(len(X.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "71e42c4b-8d81-47c7-b409-380c182df248",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X.isnull().any(axis=0)[i] for i in range(len(X.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "221f47b7-ca98-4387-a2b2-7ccbab44b44b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10614</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>114.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8270</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10194</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>496</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9851</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>546</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9967</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6372</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3782</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3136</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3495</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3331</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>446</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47118 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              着順  枠番  馬番    斤量     単勝  course_len horse_id jockey_id  年齢   体重  \\\n",
       "201901010101   1   1   1  54.0    1.4        18.0    10614       152   2  518   \n",
       "201901010101   7   2   2  54.0  114.7        18.0     8270        73   2  450   \n",
       "201901010101   2   3   3  54.0    3.5        18.0    10194       142   2  496   \n",
       "201901010101   3   4   4  51.0   46.6        18.0     9851       136   2  546   \n",
       "201901010101   5   5   5  54.0  140.3        18.0     9967        47   2  436   \n",
       "...           ..  ..  ..   ...    ...         ...      ...       ...  ..  ...   \n",
       "201910021212  15   6  12  52.0   17.5        26.0     6372         5   3  468   \n",
       "201910021212   5   7  13  57.0    7.7        26.0     3782        28   4  486   \n",
       "201910021212   1   7  14  57.0    4.4        26.0     3136        77   4  484   \n",
       "201910021212   3   8  15  57.0   21.9        26.0     3495        87   4  504   \n",
       "201910021212  11   8  16  55.0   15.1        26.0     3331        27   4  446   \n",
       "\n",
       "              ...  race_type_芝  race_type_ダート  race_type_障害  ground_state_良  \\\n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "...           ...          ...            ...           ...             ...   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "\n",
       "              ground_state_不良  ground_state_稍重  ground_state_重  性_牡  性_牝  性_セ  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    0    1    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "...                       ...              ...             ...  ...  ...  ...  \n",
       "201910021212                0                0               1    0    1    0  \n",
       "201910021212                0                0               1    1    0    0  \n",
       "201910021212                0                0               1    1    0    0  \n",
       "201910021212                0                0               1    1    0    0  \n",
       "201910021212                0                0               1    0    1    0  \n",
       "\n",
       "[47118 rows x 176 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "4dcc0f9b-51ac-46bf-abe1-a489cc9d10a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>...</th>\n",
       "      <th>race_type_芝</th>\n",
       "      <th>race_type_ダート</th>\n",
       "      <th>race_type_障害</th>\n",
       "      <th>ground_state_良</th>\n",
       "      <th>ground_state_不良</th>\n",
       "      <th>ground_state_稍重</th>\n",
       "      <th>ground_state_重</th>\n",
       "      <th>性_牡</th>\n",
       "      <th>性_牝</th>\n",
       "      <th>性_セ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10614</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>114.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8270</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>450</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10194</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>496</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9851</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>546</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9967</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6372</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3782</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3136</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "      <td>484</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3495</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>504</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3331</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>446</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47118 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              着順  枠番  馬番    斤量     単勝  course_len horse_id jockey_id  年齢   体重  \\\n",
       "201901010101   1   1   1  54.0    1.4        18.0    10614       152   2  518   \n",
       "201901010101   7   2   2  54.0  114.7        18.0     8270        73   2  450   \n",
       "201901010101   2   3   3  54.0    3.5        18.0    10194       142   2  496   \n",
       "201901010101   3   4   4  51.0   46.6        18.0     9851       136   2  546   \n",
       "201901010101   5   5   5  54.0  140.3        18.0     9967        47   2  436   \n",
       "...           ..  ..  ..   ...    ...         ...      ...       ...  ..  ...   \n",
       "201910021212  15   6  12  52.0   17.5        26.0     6372         5   3  468   \n",
       "201910021212   5   7  13  57.0    7.7        26.0     3782        28   4  486   \n",
       "201910021212   1   7  14  57.0    4.4        26.0     3136        77   4  484   \n",
       "201910021212   3   8  15  57.0   21.9        26.0     3495        87   4  504   \n",
       "201910021212  11   8  16  55.0   15.1        26.0     3331        27   4  446   \n",
       "\n",
       "              ...  race_type_芝  race_type_ダート  race_type_障害  ground_state_良  \\\n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "201901010101  ...            1              0             0               1   \n",
       "...           ...          ...            ...           ...             ...   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "201910021212  ...            1              0             0               0   \n",
       "\n",
       "              ground_state_不良  ground_state_稍重  ground_state_重  性_牡  性_牝  性_セ  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    0    1    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "201901010101                0                0               0    1    0    0  \n",
       "...                       ...              ...             ...  ...  ...  ...  \n",
       "201910021212                0                0               1    0    1    0  \n",
       "201910021212                0                0               1    1    0    0  \n",
       "201910021212                0                0               1    1    0    0  \n",
       "201910021212                0                0               1    1    0    0  \n",
       "201910021212                0                0               1    0    1    0  \n",
       "\n",
       "[47118 rows x 176 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X#.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5393cdda-5202-4d31-8ce5-ba7c4c1d333d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47118, 176)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ba78a736-7917-4bfb-9a32-ea5514d8e806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14103, 176)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "160c1700-ff71-41d8-812f-2a76169aedaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['着順',\n",
       " '枠番',\n",
       " '馬番',\n",
       " '斤量',\n",
       " '単勝',\n",
       " 'course_len',\n",
       " 'date',\n",
       " 'horse_id',\n",
       " 'jockey_id',\n",
       " 'rank',\n",
       " '年齢',\n",
       " '体重',\n",
       " '体重変化',\n",
       " 'second',\n",
       " 'rls',\n",
       " 'n_horses',\n",
       " '着順_5R',\n",
       " '賞金_5R',\n",
       " '着差_5R',\n",
       " 'first_corner_5R',\n",
       " 'first_to_rank_5R',\n",
       " 'first_to_final_5R',\n",
       " 'final_to_rank_5R',\n",
       " '着順_course_len_5R',\n",
       " '賞金_course_len_5R',\n",
       " '着差_course_len_5R',\n",
       " 'first_corner_course_len_5R',\n",
       " 'first_to_rank_course_len_5R',\n",
       " 'first_to_final_course_len_5R',\n",
       " 'final_to_rank_course_len_5R',\n",
       " '着順_race_type_5R',\n",
       " '賞金_race_type_5R',\n",
       " '着差_race_type_5R',\n",
       " 'first_corner_race_type_5R',\n",
       " 'first_to_rank_race_type_5R',\n",
       " 'first_to_final_race_type_5R',\n",
       " 'final_to_rank_race_type_5R',\n",
       " '着順_開催_5R',\n",
       " '賞金_開催_5R',\n",
       " '着差_開催_5R',\n",
       " 'first_corner_開催_5R',\n",
       " 'first_to_rank_開催_5R',\n",
       " 'first_to_final_開催_5R',\n",
       " 'final_to_rank_開催_5R',\n",
       " '着順_9R',\n",
       " '賞金_9R',\n",
       " '着差_9R',\n",
       " 'first_corner_9R',\n",
       " 'first_to_rank_9R',\n",
       " 'first_to_final_9R',\n",
       " 'final_to_rank_9R',\n",
       " '着順_course_len_9R',\n",
       " '賞金_course_len_9R',\n",
       " '着差_course_len_9R',\n",
       " 'first_corner_course_len_9R',\n",
       " 'first_to_rank_course_len_9R',\n",
       " 'first_to_final_course_len_9R',\n",
       " 'final_to_rank_course_len_9R',\n",
       " '着順_race_type_9R',\n",
       " '賞金_race_type_9R',\n",
       " '着差_race_type_9R',\n",
       " 'first_corner_race_type_9R',\n",
       " 'first_to_rank_race_type_9R',\n",
       " 'first_to_final_race_type_9R',\n",
       " 'final_to_rank_race_type_9R',\n",
       " '着順_開催_9R',\n",
       " '賞金_開催_9R',\n",
       " '着差_開催_9R',\n",
       " 'first_corner_開催_9R',\n",
       " 'first_to_rank_開催_9R',\n",
       " 'first_to_final_開催_9R',\n",
       " 'final_to_rank_開催_9R',\n",
       " '着順_allR',\n",
       " '賞金_allR',\n",
       " '着差_allR',\n",
       " 'first_corner_allR',\n",
       " 'first_to_rank_allR',\n",
       " 'first_to_final_allR',\n",
       " 'final_to_rank_allR',\n",
       " '着順_course_len_allR',\n",
       " '賞金_course_len_allR',\n",
       " '着差_course_len_allR',\n",
       " 'first_corner_course_len_allR',\n",
       " 'first_to_rank_course_len_allR',\n",
       " 'first_to_final_course_len_allR',\n",
       " 'final_to_rank_course_len_allR',\n",
       " '着順_race_type_allR',\n",
       " '賞金_race_type_allR',\n",
       " '着差_race_type_allR',\n",
       " 'first_corner_race_type_allR',\n",
       " 'first_to_rank_race_type_allR',\n",
       " 'first_to_final_race_type_allR',\n",
       " 'final_to_rank_race_type_allR',\n",
       " '着順_開催_allR',\n",
       " '賞金_開催_allR',\n",
       " '着差_開催_allR',\n",
       " 'first_corner_開催_allR',\n",
       " 'first_to_rank_開催_allR',\n",
       " 'first_to_final_開催_allR',\n",
       " 'final_to_rank_開催_allR',\n",
       " 'peds_0',\n",
       " 'peds_1',\n",
       " 'peds_2',\n",
       " 'peds_3',\n",
       " 'peds_4',\n",
       " 'peds_5',\n",
       " 'peds_6',\n",
       " 'peds_7',\n",
       " 'peds_8',\n",
       " 'peds_9',\n",
       " 'peds_10',\n",
       " 'peds_11',\n",
       " 'peds_12',\n",
       " 'peds_13',\n",
       " 'peds_14',\n",
       " 'peds_15',\n",
       " 'peds_16',\n",
       " 'peds_17',\n",
       " 'peds_18',\n",
       " 'peds_19',\n",
       " 'peds_20',\n",
       " 'peds_21',\n",
       " 'peds_22',\n",
       " 'peds_23',\n",
       " 'peds_24',\n",
       " 'peds_25',\n",
       " 'peds_26',\n",
       " 'peds_27',\n",
       " 'peds_28',\n",
       " 'peds_29',\n",
       " 'peds_30',\n",
       " 'peds_31',\n",
       " 'peds_32',\n",
       " 'peds_33',\n",
       " 'peds_34',\n",
       " 'peds_35',\n",
       " 'peds_36',\n",
       " 'peds_37',\n",
       " 'peds_38',\n",
       " 'peds_39',\n",
       " 'peds_40',\n",
       " 'peds_41',\n",
       " 'peds_42',\n",
       " 'peds_43',\n",
       " 'peds_44',\n",
       " 'peds_45',\n",
       " 'peds_46',\n",
       " 'peds_47',\n",
       " 'peds_48',\n",
       " 'peds_49',\n",
       " 'peds_50',\n",
       " 'peds_51',\n",
       " 'peds_52',\n",
       " 'peds_53',\n",
       " 'peds_54',\n",
       " 'peds_55',\n",
       " 'peds_56',\n",
       " 'peds_57',\n",
       " 'peds_58',\n",
       " 'peds_59',\n",
       " 'peds_60',\n",
       " 'peds_61',\n",
       " 'weather_曇',\n",
       " 'weather_晴',\n",
       " 'weather_小雨',\n",
       " 'weather_雨',\n",
       " 'weather_小雪',\n",
       " 'weather_雪',\n",
       " 'race_type_芝',\n",
       " 'race_type_ダート',\n",
       " 'race_type_障害',\n",
       " 'ground_state_良',\n",
       " 'ground_state_不良',\n",
       " 'ground_state_稍重',\n",
       " 'ground_state_重',\n",
       " '性_牡',\n",
       " '性_牝',\n",
       " '性_セ']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r.data_c.columns[i] for i in range(len(r.data_c.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "22ffcbcd-27af-4c3d-80ca-6bdb63cc604c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>着順</th>\n",
       "      <th>枠番</th>\n",
       "      <th>馬番</th>\n",
       "      <th>斤量</th>\n",
       "      <th>単勝</th>\n",
       "      <th>course_len</th>\n",
       "      <th>weather</th>\n",
       "      <th>race_type</th>\n",
       "      <th>ground_state</th>\n",
       "      <th>horse_id</th>\n",
       "      <th>jockey_id</th>\n",
       "      <th>性</th>\n",
       "      <th>年齢</th>\n",
       "      <th>体重</th>\n",
       "      <th>体重変化</th>\n",
       "      <th>second</th>\n",
       "      <th>rls</th>\n",
       "      <th>開催</th>\n",
       "      <th>n_horses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017105318</td>\n",
       "      <td>05339</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>518</td>\n",
       "      <td>-16</td>\n",
       "      <td>156.3</td>\n",
       "      <td>2.247616</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017104612</td>\n",
       "      <td>05203</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>496</td>\n",
       "      <td>-8</td>\n",
       "      <td>160.1</td>\n",
       "      <td>2.252953</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017103879</td>\n",
       "      <td>01180</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>546</td>\n",
       "      <td>6</td>\n",
       "      <td>160.9</td>\n",
       "      <td>2.254059</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>56.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017106259</td>\n",
       "      <td>01179</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>458</td>\n",
       "      <td>-8</td>\n",
       "      <td>162.5</td>\n",
       "      <td>2.256253</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201901010101</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>54.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>良</td>\n",
       "      <td>2017104140</td>\n",
       "      <td>01062</td>\n",
       "      <td>牡</td>\n",
       "      <td>2</td>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "      <td>162.7</td>\n",
       "      <td>2.256526</td>\n",
       "      <td>01</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>56.0</td>\n",
       "      <td>120.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2013104167</td>\n",
       "      <td>01165</td>\n",
       "      <td>セ</td>\n",
       "      <td>6</td>\n",
       "      <td>458</td>\n",
       "      <td>8</td>\n",
       "      <td>210.7</td>\n",
       "      <td>2.313101</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2014105643</td>\n",
       "      <td>01178</td>\n",
       "      <td>牡</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>2</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2.314430</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>99.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2015102081</td>\n",
       "      <td>01176</td>\n",
       "      <td>牡</td>\n",
       "      <td>4</td>\n",
       "      <td>478</td>\n",
       "      <td>14</td>\n",
       "      <td>212.2</td>\n",
       "      <td>2.314634</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2016104221</td>\n",
       "      <td>00666</td>\n",
       "      <td>牝</td>\n",
       "      <td>3</td>\n",
       "      <td>468</td>\n",
       "      <td>2</td>\n",
       "      <td>212.2</td>\n",
       "      <td>2.314634</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201910021212</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>55.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>曇</td>\n",
       "      <td>芝</td>\n",
       "      <td>重</td>\n",
       "      <td>2015100531</td>\n",
       "      <td>01128</td>\n",
       "      <td>牝</td>\n",
       "      <td>4</td>\n",
       "      <td>450</td>\n",
       "      <td>8</td>\n",
       "      <td>214.0</td>\n",
       "      <td>2.316458</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47118 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              着順  枠番  馬番    斤量     単勝  course_len weather race_type  \\\n",
       "201901010101   1   1   1  54.0    1.4        18.0       曇         芝   \n",
       "201901010101   2   3   3  54.0    3.5        18.0       曇         芝   \n",
       "201901010101   3   4   4  51.0   46.6        18.0       曇         芝   \n",
       "201901010101   4   8   9  51.0   56.8        18.0       曇         芝   \n",
       "201901010101   5   5   5  54.0  140.3        18.0       曇         芝   \n",
       "...           ..  ..  ..   ...    ...         ...     ...       ...   \n",
       "201910021212  12   6  11  56.0  120.3        26.0       曇         芝   \n",
       "201910021212  13   1   1  54.0    7.5        26.0       曇         芝   \n",
       "201910021212  14   2   3  54.0   99.2        26.0       曇         芝   \n",
       "201910021212  15   6  12  52.0   17.5        26.0       曇         芝   \n",
       "201910021212  16   2   4  55.0  110.3        26.0       曇         芝   \n",
       "\n",
       "             ground_state    horse_id jockey_id  性  年齢   体重  体重変化  second  \\\n",
       "201901010101            良  2017105318     05339  牡   2  518   -16   156.3   \n",
       "201901010101            良  2017104612     05203  牡   2  496    -8   160.1   \n",
       "201901010101            良  2017103879     01180  牡   2  546     6   160.9   \n",
       "201901010101            良  2017106259     01179  牡   2  458    -8   162.5   \n",
       "201901010101            良  2017104140     01062  牡   2  436     0   162.7   \n",
       "...                   ...         ...       ... ..  ..  ...   ...     ...   \n",
       "201910021212            重  2013104167     01165  セ   6  458     8   210.7   \n",
       "201910021212            重  2014105643     01178  牡   5  460     2   212.0   \n",
       "201910021212            重  2015102081     01176  牡   4  478    14   212.2   \n",
       "201910021212            重  2016104221     00666  牝   3  468     2   212.2   \n",
       "201910021212            重  2015100531     01128  牝   4  450     8   214.0   \n",
       "\n",
       "                   rls  開催  n_horses  \n",
       "201901010101  2.247616  01         9  \n",
       "201901010101  2.252953  01         9  \n",
       "201901010101  2.254059  01         9  \n",
       "201901010101  2.256253  01         9  \n",
       "201901010101  2.256526  01         9  \n",
       "...                ...  ..       ...  \n",
       "201910021212  2.313101  10        16  \n",
       "201910021212  2.314430  10        16  \n",
       "201910021212  2.314634  10        16  \n",
       "201910021212  2.314634  10        16  \n",
       "201910021212  2.316458  10        16  \n",
       "\n",
       "[47118 rows x 19 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9a2ea16e-2a9d-4277-8420-26c8eb1e0ede",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 130582 entries, 201901010101 to 202110040812\n",
      "Data columns (total 21 columns):\n",
      " #   Column        Non-Null Count   Dtype         \n",
      "---  ------        --------------   -----         \n",
      " 0   着順            130582 non-null  int64         \n",
      " 1   枠番            130582 non-null  int64         \n",
      " 2   馬番            130582 non-null  int64         \n",
      " 3   斤量            130582 non-null  float64       \n",
      " 4   単勝            130582 non-null  float64       \n",
      " 5   course_len    47118 non-null   float64       \n",
      " 6   weather       130582 non-null  object        \n",
      " 7   race_type     130582 non-null  object        \n",
      " 8   ground_state  130582 non-null  object        \n",
      " 9   date          47118 non-null   datetime64[ns]\n",
      " 10  horse_id      130582 non-null  object        \n",
      " 11  jockey_id     130582 non-null  object        \n",
      " 12  rank          130582 non-null  int64         \n",
      " 13  性             130582 non-null  object        \n",
      " 14  年齢            130582 non-null  int64         \n",
      " 15  体重            130582 non-null  int64         \n",
      " 16  体重変化          130582 non-null  int64         \n",
      " 17  second        130582 non-null  float64       \n",
      " 18  rls           130582 non-null  float64       \n",
      " 19  開催            130582 non-null  object        \n",
      " 20  n_horses      130582 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(5), int64(8), object(7)\n",
      "memory usage: 25.9+ MB\n"
     ]
    }
   ],
   "source": [
    "r.data_p.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5e2545fa-e8b7-4c57-8b78-98898206790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = r.data_c.fillna(0).drop([\"date\"],axis=1)\n",
    "y = r.data_c[\"rls\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "18437810-2f21-407a-ba58-530ffcb11bc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "777af4a7-95f5-413d-a0bf-5db1482354dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d40b0-c102-4245-91a9-41fd7574494d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
